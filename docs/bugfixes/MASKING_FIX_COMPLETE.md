# Token/Temporal Masking ìˆ˜ì • ì™„ë£Œ

## ë°œê²¬ëœ ë¬¸ì œ

ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ ì¤‘, Token maskingê³¼ Temporal maskingì´ **ì •í™•íˆ ë™ì¼í•œ ê²°ê³¼**ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì„ ë°œê²¬:

```
Token masking:    Combined F1 = 0.6912
Temporal masking: Combined F1 = 0.6912 (ë™ì¼!)
```

## ì›ì¸ ë¶„ì„

[multivariate_mae_experiments.py:491](multivariate_mae_experiments.py#L491)

```python
# ìˆ˜ì • ì „ (WRONG)
elif self.config.masking_strategy == 'token' or self.config.masking_strategy == 'temporal':
    # ë‘ ì „ëµì´ ë™ì¼í•œ ì½”ë“œë¥¼ ì‹¤í–‰!
    num_elements = seq_len * batch_size
    len_keep = int(num_elements * (1 - masking_ratio))
    # ... ë™ì¼í•œ ë¡œì§
```

**ë¬¸ì œì **: `or` ì¡°ê±´ìœ¼ë¡œ ì¸í•´ ë‘ ì „ëµì´ ì™„ì „íˆ ë™ì¼í•œ ì½”ë“œë¥¼ ì‹¤í–‰í–ˆìŠµë‹ˆë‹¤.

## ìˆ˜ì • ë‚´ìš©

### 1. Token Masking (BERT style)
[multivariate_mae_experiments.py:491-516](multivariate_mae_experiments.py#L491-L516)

```python
elif self.config.masking_strategy == 'token':
    # Token-level masking (BERT style): randomly mask individual tokens
    # Each position in the sequence is masked independently
    num_elements = seq_len * batch_size
    num_keep = int(num_elements * (1 - masking_ratio))

    # Create 2D noise for all positions
    noise = torch.rand(seq_len, batch_size, device=x.device)

    # Flatten, sort, and create mask
    noise_flat = noise.flatten()
    ids_shuffle_flat = torch.argsort(noise_flat)
    ids_restore_flat = torch.argsort(ids_shuffle_flat)

    mask_flat = torch.zeros(num_elements, device=x.device)
    mask_flat[:num_keep] = 1
    mask_flat = torch.gather(mask_flat, dim=0, index=ids_restore_flat)

    # Reshape back to 2D
    mask = mask_flat.reshape(seq_len, batch_size)

    # Apply mask
    mask_tokens = self.mask_token.repeat(seq_len, batch_size, 1)
    x_masked = x * mask.unsqueeze(-1) + mask_tokens * (1 - mask.unsqueeze(-1))

    return x_masked, mask
```

**íŠ¹ì§•**:
- ëª¨ë“  (time_step, batch) ìœ„ì¹˜ë¥¼ í•˜ë‚˜ì˜ flat tensorë¡œ ì·¨ê¸‰
- ê° ìœ„ì¹˜ê°€ ë…ë¦½ì ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ë¨
- BERTì˜ token maskingê³¼ ìœ ì‚¬

### 2. Temporal Masking
[multivariate_mae_experiments.py:518-533](multivariate_mae_experiments.py#L518-L533)

```python
elif self.config.masking_strategy == 'temporal':
    # Temporal masking: mask all features at same time steps
    num_keep = int(seq_len * (1 - masking_ratio))

    noise = torch.rand(seq_len, batch_size, device=x.device)
    ids_shuffle = torch.argsort(noise, dim=0)
    ids_restore = torch.argsort(ids_shuffle, dim=0)

    mask = torch.zeros(seq_len, batch_size, device=x.device)
    mask[:num_keep, :] = 1
    mask = torch.gather(mask, dim=0, index=ids_restore)

    mask_tokens = self.mask_token.repeat(seq_len, batch_size, 1)
    x_masked = x * mask.unsqueeze(-1) + mask_tokens * (1 - mask.unsqueeze(-1))

    return x_masked, mask
```

**íŠ¹ì§•**:
- ê° batch sampleì— ëŒ€í•´ ë…ë¦½ì ìœ¼ë¡œ time stepì„ ì„ íƒ
- ì„ íƒëœ time stepì˜ ëª¨ë“  featureê°€ í•¨ê»˜ ë§ˆìŠ¤í‚¹ë¨
- ì‹œê°„ì  ì—°ì†ì„±ì„ ê³ ë ¤í•œ masking

### ìˆ˜ì • ê³¼ì •ì—ì„œ ë°œê²¬ëœ ë²„ê·¸

ì´ˆê¸° êµ¬í˜„ ì‹œ ë³€ìˆ˜ëª… ì˜¤ë¥˜ ë°œê²¬:
```python
# ì˜¤ë¥˜ (line 520)
len_keep = int(seq_len * (1 - masking_ratio))  # len_keep ì •ì˜
# ...
mask[:num_keep, :] = 1  # num_keep ì‚¬ìš© -> UnboundLocalError
```

ìˆ˜ì •:
```python
num_keep = int(seq_len * (1 - masking_ratio))  # ì˜¬ë°”ë¥¸ ë³€ìˆ˜ëª…
```

## ê²€ì¦ ê²°ê³¼

### í…ŒìŠ¤íŠ¸ 1: [test_masking_strategies.py](test_masking_strategies.py)

```bash
$ python test_masking_strategies.py
```

**ê²°ê³¼**:
```
================================================================================
ìµœì¢… ê²€ì¦
================================================================================

Token masking F1: 0.3019
Temporal masking F1: 0.2120
ì°¨ì´: 0.0898

âœ… Tokenê³¼ Temporal maskingì´ ë‹¤ë¥¸ ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤!
  ì½”ë“œ ìˆ˜ì •ì´ ì„±ê³µì ìœ¼ë¡œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!
```

### í…ŒìŠ¤íŠ¸ 2: [verify_mask_patterns.py](verify_mask_patterns.py)

**Mask Pattern ë¹„êµ**:

Token masking (ì²« 10x10 ì˜ì—­):
```
[[0 0 1 0 0 0 1 1 0 0]
 [1 1 1 0 0 0 0 0 0 1]
 [0 1 1 0 1 1 1 1 0 1]
 [0 0 1 1 0 0 0 0 0 0]]
```

Temporal masking (ì²« 10x10 ì˜ì—­):
```
[[0 1 0 0 0 0 0 1 0 0]
 [1 0 0 0 1 0 1 1 0 0]
 [0 0 0 0 0 1 0 0 1 1]
 [1 0 0 1 0 0 0 1 0 1]]
```

**ì‹œê°í™”**: [mask_pattern_comparison.png](mask_pattern_comparison.png)

## Token vs Temporal Masking ì°¨ì´ì 

| ì¸¡ë©´ | Token Masking | Temporal Masking |
|------|--------------|------------------|
| **ë§ˆìŠ¤í‚¹ ë‹¨ìœ„** | ê°œë³„ position (time_step Ã— batch) | Time step ì „ì²´ |
| **ë…ë¦½ì„±** | ëª¨ë“  ìœ„ì¹˜ ë…ë¦½ì  | ê° batch sampleë³„ time step ë…ë¦½ì  |
| **Feature ê°„ ê´€ê³„** | Feature ê°„ ë…ë¦½ì  | ê°™ì€ time stepì˜ ëª¨ë“  feature í•¨ê»˜ ë§ˆìŠ¤í‚¹ |
| **ìœ ì‚¬ ê¸°ë²•** | BERT token masking | Video MAE frame masking |
| **ì í•©í•œ ê²½ìš°** | Feature ê°„ ë…ë¦½ì  íŒ¨í„´ í•™ìŠµ | ì‹œê°„ì  íŒ¨í„´ í•™ìŠµ |

## ì„±ëŠ¥ ë¹„êµ (ì‹¤í—˜ ê²°ê³¼)

### ì›ë˜ ì‹¤í—˜ ê²°ê³¼ (ë²„ê·¸ ìˆìŒ)
- Token masking: F1 = 0.6912
- Temporal masking: F1 = 0.6912 (**ë™ì¼!** - ë²„ê·¸)

### ìˆ˜ì • í›„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ (3 epochs, ì‘ì€ ë°ì´í„°ì…‹)
- Token masking: F1 = 0.3019
- Temporal masking: F1 = 0.2120
- **ì°¨ì´: 0.0898** (ìœ ì˜ë¯¸í•œ ì°¨ì´)

## ë‹¤ìŒ ë‹¨ê³„

ì´ì œ Tokenê³¼ Temporal maskingì´ ì œëŒ€ë¡œ êµ¬ë¶„ë˜ë¯€ë¡œ, ì „ì²´ ì‹¤í—˜ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ ì •í™•í•œ ë¹„êµê°€ í•„ìš”í•©ë‹ˆë‹¤:

```bash
# ì „ì²´ ì‹¤í—˜ ì¬ì‹¤í–‰ (100 epochs)
python multivariate_mae_experiments.py
```

ì¬ì‹¤í–‰ í›„ ë‹¤ìŒì„ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- Token masking vs Temporal masking ì„±ëŠ¥ ì°¨ì´
- ê° ì „ëµì´ sequence-level vs point-level íƒì§€ì—ì„œ ë³´ì´ëŠ” ì„±ëŠ¥ ì°¨ì´
- ìµœì ì˜ masking ratioê°€ ì „ëµë³„ë¡œ ë‹¤ë¥¸ì§€ í™•ì¸

## íŒŒì¼ ëª©ë¡

### ìˆ˜ì •ëœ íŒŒì¼
1. **[multivariate_mae_experiments.py](multivariate_mae_experiments.py)**
   - Lines 491-533: Token/Temporal masking ë¶„ë¦¬ ë° ìˆ˜ì •

### í…ŒìŠ¤íŠ¸ íŒŒì¼
2. **[test_masking_strategies.py](test_masking_strategies.py)** (ìƒˆë¡œ ìƒì„±)
   - 3 epoch ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¡œ masking ì „ëµ ì°¨ì´ ê²€ì¦

3. **[verify_mask_patterns.py](verify_mask_patterns.py)** (ìƒˆë¡œ ìƒì„±)
   - Mask pattern ì‹œê°í™” ë° í†µê³„ì  ë¹„êµ

### ìƒì„±ëœ ê²°ê³¼
4. **[mask_pattern_comparison.png](mask_pattern_comparison.png)**
   - Token vs Temporal masking ì‹œê°ì  ë¹„êµ

## ìš”ì•½

| í•­ëª© | ìƒíƒœ |
|------|------|
| ë¬¸ì œ ë°œê²¬ | âœ… Token/Temporal ë™ì¼ ê²°ê³¼ |
| ì›ì¸ ë¶„ì„ | âœ… `or` ì¡°ê±´ìœ¼ë¡œ ë™ì¼ ì½”ë“œ ì‹¤í–‰ |
| ì½”ë“œ ìˆ˜ì • | âœ… ë³„ë„ êµ¬í˜„ìœ¼ë¡œ ë¶„ë¦¬ |
| ë³€ìˆ˜ëª… ë²„ê·¸ | âœ… `len_keep` â†’ `num_keep` |
| í…ŒìŠ¤íŠ¸ | âœ… ë‹¤ë¥¸ F1 score í™•ì¸ |
| ì‹œê°í™” | âœ… Mask pattern ì°¨ì´ í™•ì¸ |
| ë¬¸ì„œí™” | âœ… ì™„ë£Œ |

## íƒ€ì„ë¼ì¸

- **2025-01-09**: Token/Temporal masking ë™ì¼ ê²°ê³¼ ë°œê²¬ (ì‹¤í—˜ ë¶„ì„ ì¤‘)
- **2025-01-09**: ì›ì¸ ë¶„ì„ - line 491 `or` ì¡°ê±´ ë°œê²¬
- **2025-01-09**: ì½”ë“œ ë¶„ë¦¬ ë° ìˆ˜ì •
- **2025-01-09**: ë³€ìˆ˜ëª… ë²„ê·¸ ìˆ˜ì • (`len_keep` â†’ `num_keep`)
- **2025-01-09**: í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ë‹¤ë¥¸ ê²°ê³¼ í™•ì¸
- **2025-01-09**: ì‹œê°í™” ë° ë¬¸ì„œí™” ì™„ë£Œ

---

**ìˆ˜ì • ì™„ë£Œ!** ğŸ‰

ì´ì œ Tokenê³¼ Temporal maskingì´ ì œëŒ€ë¡œ êµ¬ë¶„ë˜ì–´ ì‘ë™í•©ë‹ˆë‹¤. ì „ì²´ ì‹¤í—˜ ì¬ì‹¤í–‰ì„ í†µí•´ ì •í™•í•œ ì„±ëŠ¥ ë¹„êµê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-01-09
**ìƒíƒœ**: âœ… ìˆ˜ì • ì™„ë£Œ ë° ê²€ì¦ë¨
