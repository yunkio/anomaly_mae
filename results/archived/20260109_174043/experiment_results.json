[
  {
    "experiment_name": "Baseline",
    "config": {
      "seq_length": 100,
      "num_features": 5,
      "num_train_samples": 1000,
      "num_test_samples": 300,
      "train_anomaly_ratio": 0.05,
      "test_anomaly_ratio": 0.25,
      "d_model": 64,
      "nhead": 4,
      "num_encoder_layers": 3,
      "num_teacher_decoder_layers": 4,
      "num_student_decoder_layers": 1,
      "dim_feedforward": 256,
      "dropout": 0.1,
      "masking_ratio": 0.6,
      "masking_strategy": "patch",
      "patch_size": 10,
      "margin": 1.0,
      "lambda_disc": 0.5,
      "batch_size": 32,
      "num_epochs": 100,
      "learning_rate": 0.001,
      "weight_decay": 1e-05,
      "warmup_epochs": 10,
      "mask_last_n": 10,
      "use_discrepancy_loss": true,
      "use_teacher": true,
      "use_student": true,
      "use_masking": true,
      "random_seed": 42,
      "device": "cuda"
    },
    "metrics": {
      "sequence": {
        "roc_auc": 0.745362962962963,
        "precision": 0.9024390243902439,
        "recall": 0.49333333333333335,
        "f1_score": 0.6379310344827587,
        "optimal_threshold": 0.07933273166418076
      },
      "point": {
        "roc_auc": 0.7482150434653644,
        "precision": 0.3288439955106622,
        "recall": 0.5671699574138599,
        "f1_score": 0.4163114521170787,
        "optimal_threshold": 0.04990878328680992
      },
      "combined": {
        "roc_auc": 0.7464892254600655,
        "precision": 0.6759311929992327,
        "recall": 0.5224907924389011,
        "f1_score": 0.5504153335648376,
        "seq_weight": 0.6051084476212164,
        "point_weight": 0.39489155237878354
      }
    },
    "history": {
      "train_loss": [
        0.45069260662421584,
        0.24600532464683056,
        0.26216461695730686,
        0.29439063323661685,
        0.3465298870578408,
        0.3631347822956741,
        0.39896098244935274,
        0.4460703772492707,
        0.5199500108137727,
        0.5098281418904662,
        0.5608593858778477,
        0.43320857593789697,
        0.43045596638694406,
        0.4557116492651403,
        0.47581321420148015,
        0.47616616543382406,
        0.4246832481585443,
        0.50063651567325,
        0.3946522194892168,
        0.41676768800243735,
        0.4645354254171252,
        0.4448269661515951,
        0.4208258371800184,
        0.3708501972723752,
        0.41925334255211055,
        0.41202717344276607,
        0.4498936596792191,
        0.4284757920540869,
        0.40128875663504004,
        0.41250896360725164,
        0.40711268433369696,
        0.3943732383195311,
        0.37138900719583035,
        0.3637082325294614,
        0.38754785782657564,
        0.422719971742481,
        0.360121505567804,
        0.3712450307793915,
        0.37540683592669666,
        0.2822250849567354,
        0.36268930439837277,
        0.3793993969447911,
        0.38407756900414824,
        0.3988108434714377,
        0.3147265494335443,
        0.3252482063835487,
        0.3040233701467514,
        0.3282473012804985,
        0.3191215433180332,
        0.31026423117145896,
        0.3009237942751497,
        0.2863213870441541,
        0.2785054531414062,
        0.26246473274659365,
        0.30944614368490875,
        0.28926218091510236,
        0.3330000485293567,
        0.23640965961385518,
        0.2809467220213264,
        0.27085538511164486,
        0.2859509172849357,
        0.33457607065793127,
        0.25120811723172665,
        0.28418606775812805,
        0.24373586708679795,
        0.2995935339713469,
        0.2500858623534441,
        0.26324650493916124,
        0.28047673287801445,
        0.2870638673193753,
        0.24851951736491174,
        0.2552763611311093,
        0.30182501405943185,
        0.23189781501423568,
        0.23466089635621756,
        0.25235095573589206,
        0.2658318226458505,
        0.24067189125344157,
        0.19726285594515502,
        0.27139154402539134,
        0.24264398333616555,
        0.2223285953514278,
        0.2508014366030693,
        0.27155080426018685,
        0.2671032107900828,
        0.2608125809347257,
        0.24940161383710802,
        0.2758944222005084,
        0.2458530917065218,
        0.2082646763883531,
        0.23084140464197844,
        0.1855039275251329,
        0.2592771052150056,
        0.25388422317337245,
        0.2315578965935856,
        0.22449559054803103,
        0.22396757663227618,
        0.28526158712338656,
        0.2702488120412454,
        0.2387119228951633
      ],
      "train_rec_loss": [
        0.40030571911484003,
        0.20068207057192922,
        0.18160629412159324,
        0.17318867426365614,
        0.16860390873625875,
        0.16544813616201282,
        0.16259146062657237,
        0.16008594213053584,
        0.15646124351769686,
        0.1667265580035746,
        0.1708180969581008,
        0.1593720461241901,
        0.1560109881684184,
        0.15323436493054032,
        0.15376564068719745,
        0.15833824733272195,
        0.15357631025835872,
        0.1516464981250465,
        0.149103335570544,
        0.1464159651659429,
        0.14298288011923432,
        0.14601380471140146,
        0.13716415269300342,
        0.13131154817529023,
        0.12799830292351544,
        0.1266299239359796,
        0.11985041620209813,
        0.1189720572438091,
        0.11634614993818104,
        0.11110169324092567,
        0.10000653308816254,
        0.09236574987880886,
        0.09514605416916311,
        0.08640496269799769,
        0.08301415224559605,
        0.08194127038586885,
        0.07295230124145746,
        0.07211370184086263,
        0.07231569848954678,
        0.06724894011858851,
        0.06342649844009429,
        0.06438699655700475,
        0.06316123250871897,
        0.06411580624990165,
        0.06273100222460926,
        0.06125506106764078,
        0.05820282734930515,
        0.05593224288895726,
        0.05780160624999553,
        0.055767550715245306,
        0.05420995643362403,
        0.055651741684414446,
        0.054907861980609596,
        0.05159259377978742,
        0.052193645969964564,
        0.05164226342458278,
        0.050039131194353104,
        0.0504620170686394,
        0.04959069634787738,
        0.04839909030124545,
        0.04819370829500258,
        0.047318754834122956,
        0.046497604926116765,
        0.04722982726525515,
        0.047516266466118395,
        0.04721375787630677,
        0.045742307091131806,
        0.04511558695230633,
        0.04619963874574751,
        0.04666072106920183,
        0.04526612162590027,
        0.04491934704128653,
        0.04466407233849168,
        0.04513510467950255,
        0.04463470703922212,
        0.04438070231117308,
        0.04338215955067426,
        0.044060427928343415,
        0.043544193962588906,
        0.043907609418965876,
        0.04397830308880657,
        0.044309286517091095,
        0.04339679144322872,
        0.04315702128224075,
        0.04336094914469868,
        0.04376419342588633,
        0.04297037108335644,
        0.04383307043462992,
        0.04255210352130234,
        0.04292174521833658,
        0.043634721892885864,
        0.04280007118359208,
        0.043126288801431656,
        0.04278200282715261,
        0.043278926983475685,
        0.04312862444203347,
        0.0424850556300953,
        0.04288164561148733,
        0.04268651909660548,
        0.04324505990371108
      ],
      "train_disc_loss": [
        0.10077377123525366,
        0.09064650611253455,
        0.16111664465279318,
        0.24240392388310283,
        0.35585196092142724,
        0.3953732950176345,
        0.4727390389307402,
        0.5719688750541536,
        0.7269775337044848,
        0.6862031783675775,
        0.7800825831654947,
        0.5476730597147252,
        0.5488899592019152,
        0.6049545654677786,
        0.6440951480471995,
        0.6356558375409804,
        0.54221387016878,
        0.6979800360568333,
        0.49109776732802857,
        0.5407034443342127,
        0.6431050868122838,
        0.5976263213669881,
        0.5673233753477689,
        0.4790772969718091,
        0.5825100795482285,
        0.5707945075409953,
        0.6600864838401321,
        0.6190074672631454,
        0.569885206699837,
        0.6028145475429483,
        0.6142123035679106,
        0.6040149733889848,
        0.5524859023280442,
        0.5546065397793427,
        0.6090674116276205,
        0.6815573962812778,
        0.5743384025990963,
        0.598262652871199,
        0.6061822749907151,
        0.42995228769723326,
        0.5985256097628735,
        0.6300247961189598,
        0.6418326760758646,
        0.6693900725804269,
        0.5039910943014547,
        0.527986299188342,
        0.4916410924633965,
        0.5446301093325019,
        0.5226398775703274,
        0.5089933552080765,
        0.4934276784188114,
        0.46133929293137044,
        0.4471951778396033,
        0.42174428194994107,
        0.5145049893762916,
        0.475239829858765,
        0.5659218345535919,
        0.37189528107410297,
        0.4627120459335856,
        0.44491258211201057,
        0.47551441728137434,
        0.5745146269910038,
        0.4094210218754597,
        0.4739124804036692,
        0.39243920508306473,
        0.5047595487558283,
        0.40868710802169517,
        0.4362618381273933,
        0.4685541815706529,
        0.48080628423485905,
        0.4065067881019786,
        0.42071402695728466,
        0.5143218840821646,
        0.37352542398730293,
        0.3800523768295534,
        0.41594051010906696,
        0.4448993277619593,
        0.39322292478755116,
        0.3074373275740072,
        0.45496786915464327,
        0.39733135764254257,
        0.35603861924028024,
        0.41480929037788883,
        0.45678757049608976,
        0.4474845225340687,
        0.4340967769967392,
        0.4128624873701483,
        0.46412269526626915,
        0.4066019718302414,
        0.33068586100125685,
        0.37441336328629404,
        0.2854077150695957,
        0.4323016384150833,
        0.4222044410998933,
        0.37655794114107266,
        0.362733929825481,
        0.3629650465445593,
        0.48475988273276016,
        0.4551245874608867,
        0.39093372656498104
      ],
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100
      ]
    }
  },
  {
    "experiment_name": "MaskingRatio_0.4",
    "config": {
      "seq_length": 100,
      "num_features": 5,
      "num_train_samples": 1000,
      "num_test_samples": 300,
      "train_anomaly_ratio": 0.05,
      "test_anomaly_ratio": 0.25,
      "d_model": 64,
      "nhead": 4,
      "num_encoder_layers": 3,
      "num_teacher_decoder_layers": 4,
      "num_student_decoder_layers": 1,
      "dim_feedforward": 256,
      "dropout": 0.1,
      "masking_ratio": 0.4,
      "masking_strategy": "patch",
      "patch_size": 10,
      "margin": 1.0,
      "lambda_disc": 0.5,
      "batch_size": 32,
      "num_epochs": 100,
      "learning_rate": 0.001,
      "weight_decay": 1e-05,
      "warmup_epochs": 10,
      "mask_last_n": 10,
      "use_discrepancy_loss": true,
      "use_teacher": true,
      "use_student": true,
      "use_masking": true,
      "random_seed": 42,
      "device": "cuda"
    },
    "metrics": {
      "sequence": {
        "roc_auc": 0.7580444444444445,
        "precision": 0.9069767441860465,
        "recall": 0.52,
        "f1_score": 0.6610169491525424,
        "optimal_threshold": 0.07737112045288086
      },
      "point": {
        "roc_auc": 0.7677480623565347,
        "precision": 0.3695914914189026,
        "recall": 0.591947348044909,
        "f1_score": 0.4550595238095238,
        "optimal_threshold": 0.058002036064863205
      },
      "combined": {
        "roc_auc": 0.762000915038781,
        "precision": 0.6878678541137899,
        "recall": 0.549335199454372,
        "f1_score": 0.5770416211421874,
        "seq_weight": 0.5922685095208609,
        "point_weight": 0.40773149047913904
      }
    },
    "history": {
      "train_loss": [
        0.44152594823390245,
        0.24759717844426632,
        0.2643509334884584,
        0.29618270695209503,
        0.3474928680807352,
        0.3649743958376348,
        0.3990909894928336,
        0.4427367108874023,
        0.5199609277769923,
        0.5344177102670074,
        0.4946696653496474,
        0.43903914792463183,
        0.4042123267427087,
        0.44230256834998727,
        0.46457305224612355,
        0.4652081597596407,
        0.43938095727935433,
        0.459480881690979,
        0.3827379224821925,
        0.41182767134159803,
        0.46026513748802245,
        0.41885614208877087,
        0.3882015501148999,
        0.3305529907811433,
        0.35934005794115365,
        0.36729480675421655,
        0.39052409562282264,
        0.3560809150803834,
        0.36998017644509673,
        0.329431013436988,
        0.3422361093107611,
        0.3429341570008546,
        0.33752589556388557,
        0.3249267579521984,
        0.32030051143374294,
        0.32775083440355957,
        0.329728907905519,
        0.2948694955557585,
        0.2890382423065603,
        0.24389728135429323,
        0.26390306337270886,
        0.28126279450953007,
        0.2914952194551006,
        0.29998321062885225,
        0.2592080974718556,
        0.24013085244223475,
        0.2569356607273221,
        0.24429496191442013,
        0.22725305485073477,
        0.213720019091852,
        0.24357880058232695,
        0.22100772301200777,
        0.20992379006929696,
        0.229366201790981,
        0.22800383938010782,
        0.21176527498755604,
        0.25342729105614126,
        0.19605262344703078,
        0.21985504985786974,
        0.19403448223602027,
        0.24413801520131528,
        0.2635572333820164,
        0.19230257463641465,
        0.2164719180436805,
        0.17196046793833375,
        0.2214202641043812,
        0.2063602562993765,
        0.19134149746969342,
        0.21107172314077616,
        0.2174963162979111,
        0.1911127408966422,
        0.23213545104954392,
        0.19426770776044577,
        0.17201884579844773,
        0.1716233332408592,
        0.19984057021792978,
        0.22164632729254663,
        0.17335579171776772,
        0.15755029453430325,
        0.1884874814422801,
        0.17052393849007785,
        0.14657528314273804,
        0.1613170652417466,
        0.16156244557350874,
        0.19538212264887989,
        0.1914659773465246,
        0.16848227102309465,
        0.1708309423411265,
        0.14460347243584692,
        0.16020028956700116,
        0.17047046101652086,
        0.1204819317208603,
        0.14267878630198538,
        0.19709100958425552,
        0.16031223838217556,
        0.15554696135222912,
        0.1550426062894985,
        0.1785177739802748,
        0.20411981793586165,
        0.15789754036813974
      ],
      "train_rec_loss": [
        0.3918605409562588,
        0.20228265598416328,
        0.18377335416153073,
        0.17496351432055235,
        0.16941431490704417,
        0.16716467961668968,
        0.1625664378516376,
        0.1566172013990581,
        0.16090561542659998,
        0.18186186347156763,
        0.16184948617592454,
        0.15752332704141736,
        0.1562370965257287,
        0.14990033395588398,
        0.14538706513121724,
        0.1472380398772657,
        0.15018201945349574,
        0.1434125262312591,
        0.13622035388834774,
        0.1412956709973514,
        0.1317321544047445,
        0.12637816555798054,
        0.11656845943070948,
        0.10755638545379043,
        0.1049527598079294,
        0.10067253396846354,
        0.09742026310414076,
        0.09140799008309841,
        0.08192289364524186,
        0.0799901878926903,
        0.07526201219297945,
        0.07193079148419201,
        0.07506530196405947,
        0.07253088301513344,
        0.06568424834404141,
        0.061905721202492714,
        0.06067715282551944,
        0.06296129280235618,
        0.06150789256207645,
        0.05984250956680626,
        0.0585824433946982,
        0.05586656439118087,
        0.0584897066000849,
        0.05534078844357282,
        0.05302347580436617,
        0.05104765691794455,
        0.05208451859652996,
        0.051496468018740416,
        0.05054887814912945,
        0.04917044343892485,
        0.04830042505636811,
        0.049427071935497224,
        0.04803571407683194,
        0.04650212067645043,
        0.04652822611387819,
        0.045902157900854945,
        0.04495291877537966,
        0.04586864705197513,
        0.044424295192584395,
        0.04497118527069688,
        0.044112096540629864,
        0.04443953663576394,
        0.043682019342668355,
        0.04408518865238875,
        0.04356902069412172,
        0.04309142066631466,
        0.042516425950452685,
        0.04256494319997728,
        0.042678816709667444,
        0.04267288080882281,
        0.042305289302021265,
        0.04204596229828894,
        0.0416954014217481,
        0.041252362192608416,
        0.041264230967499316,
        0.04146679968107492,
        0.04114484565798193,
        0.041030635009519756,
        0.041689509293064475,
        0.04071700572967529,
        0.04175410361494869,
        0.04118143976666033,
        0.04103718081023544,
        0.040825868491083384,
        0.040961479186080396,
        0.04028839454986155,
        0.04024776164442301,
        0.04086418333463371,
        0.03954454744234681,
        0.03983906423673034,
        0.040603820350952446,
        0.0397903771372512,
        0.04027248464990407,
        0.03994988778140396,
        0.04040456470102072,
        0.040299969958141446,
        0.04006023926194757,
        0.03960479097440839,
        0.03985037829261273,
        0.03982951364014298
      ],
      "train_disc_loss": [
        0.09933082578936592,
        0.09062904413440265,
        0.16115516060381196,
        0.2424383862526156,
        0.35615710832644254,
        0.39561943386797793,
        0.47304910625098273,
        0.5722390123119112,
        0.7181106270872988,
        0.7051116974907927,
        0.6656403593660798,
        0.5630316406895872,
        0.4959504638100043,
        0.5848044701269828,
        0.6383719714067411,
        0.6359402432572097,
        0.5783978677645791,
        0.6321367078635376,
        0.4930351315124426,
        0.5410640093323309,
        0.6570659663702827,
        0.5849559544876684,
        0.5432661800296046,
        0.4459932144964114,
        0.5087745974306017,
        0.5332445488020312,
        0.5862076638150029,
        0.5293458469677716,
        0.5761145596625283,
        0.4988816534169018,
        0.5339481961564161,
        0.542006730043795,
        0.5249211841728538,
        0.5047917470801622,
        0.5092325243749656,
        0.5316902319318615,
        0.5381035062600859,
        0.46381640259642154,
        0.4550606987904757,
        0.36810954235261306,
        0.4106412405963056,
        0.4507924636709504,
        0.4660110265831463,
        0.48928484017960727,
        0.41236924414988607,
        0.37816639232914895,
        0.4097022821661085,
        0.38559698581229895,
        0.35340835410170257,
        0.32909914635820314,
        0.39055675111012533,
        0.34316130058141425,
        0.3237761486088857,
        0.36572816217085347,
        0.36295122595038265,
        0.3317262359778397,
        0.4169487523031421,
        0.30036795244086534,
        0.35086150863207877,
        0.2981265940470621,
        0.40005183743778616,
        0.438235392794013,
        0.2972411084920168,
        0.34477345849154517,
        0.2567828968167305,
        0.35665768856415525,
        0.32768765807850286,
        0.29755311051849276,
        0.3367858116980642,
        0.34964687295723706,
        0.2976149092428386,
        0.38017897290410474,
        0.3051446115132421,
        0.261532969889231,
        0.2607182037900202,
        0.31674754089908674,
        0.36100296227959916,
        0.2646503097494133,
        0.23172156768850982,
        0.2955409489222802,
        0.25753967551281676,
        0.21078768919687718,
        0.24055976938689128,
        0.24147315870504826,
        0.30884128843899816,
        0.3023551703663543,
        0.25646901852451265,
        0.2599335191771388,
        0.21011785199516453,
        0.24072244972921908,
        0.2597332849400118,
        0.1613831075374037,
        0.2048126042354852,
        0.31428224116098136,
        0.23981534608174115,
        0.23049398223520257,
        0.22996473519015126,
        0.27782596423639916,
        0.3285388812655583,
        0.23613605345599353
      ],
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100
      ]
    }
  },
  {
    "experiment_name": "MaskingRatio_0.75",
    "config": {
      "seq_length": 100,
      "num_features": 5,
      "num_train_samples": 1000,
      "num_test_samples": 300,
      "train_anomaly_ratio": 0.05,
      "test_anomaly_ratio": 0.25,
      "d_model": 64,
      "nhead": 4,
      "num_encoder_layers": 3,
      "num_teacher_decoder_layers": 4,
      "num_student_decoder_layers": 1,
      "dim_feedforward": 256,
      "dropout": 0.1,
      "masking_ratio": 0.75,
      "masking_strategy": "patch",
      "patch_size": 10,
      "margin": 1.0,
      "lambda_disc": 0.5,
      "batch_size": 32,
      "num_epochs": 100,
      "learning_rate": 0.001,
      "weight_decay": 1e-05,
      "warmup_epochs": 10,
      "mask_last_n": 10,
      "use_discrepancy_loss": true,
      "use_teacher": true,
      "use_student": true,
      "use_masking": true,
      "random_seed": 42,
      "device": "cuda"
    },
    "metrics": {
      "sequence": {
        "roc_auc": 0.6334222222222222,
        "precision": 0.6976744186046512,
        "recall": 0.4,
        "f1_score": 0.5084745762711864,
        "optimal_threshold": 0.008845547214150429
      },
      "point": {
        "roc_auc": 0.6862393999749584,
        "precision": 0.25985047484340273,
        "recall": 0.4978706929926442,
        "f1_score": 0.34147636749867233,
        "optimal_threshold": 0.011600685305893421
      },
      "combined": {
        "roc_auc": 0.6546420562993989,
        "precision": 0.5217742316404304,
        "recall": 0.43932053840598506,
        "f1_score": 0.4413813609174967,
        "seq_weight": 0.5982399101951773,
        "point_weight": 0.4017600898048228
      }
    },
    "history": {
      "train_loss": [
        0.45397173846140504,
        0.24364075437188148,
        0.25987907126545906,
        0.2950552850961685,
        0.3453588583506644,
        0.36221632454544306,
        0.3996350015513599,
        0.4476773305796087,
        0.5228930017910898,
        0.53993357764557,
        0.5797022958286107,
        0.5160206099972129,
        0.4850001805461943,
        0.5504976469092071,
        0.5635065850801766,
        0.5904100108891726,
        0.4927860675379634,
        0.5226385830901563,
        0.46520045679062605,
        0.45180209539830685,
        0.49686762085184455,
        0.49277774058282375,
        0.48904407769441605,
        0.4549453039653599,
        0.5311279119923711,
        0.4831390958279371,
        0.5163866435177624,
        0.5001197797246277,
        0.4939208454452455,
        0.4634015681222081,
        0.5114900628104806,
        0.4720149035565555,
        0.48055892949923873,
        0.46338509721681476,
        0.4768335158005357,
        0.4720135969109833,
        0.451123567763716,
        0.46542365849018097,
        0.4592150691896677,
        0.42191364988684654,
        0.49026599200442433,
        0.47327777929604053,
        0.48099342873319983,
        0.5146313146688044,
        0.4541976419277489,
        0.49489147029817104,
        0.4941919753327966,
        0.4608991499990225,
        0.48500883346423507,
        0.45855168951675296,
        0.4542935388162732,
        0.5028867931105196,
        0.44921179907396436,
        0.4235761696472764,
        0.46596297109499574,
        0.4451372059993446,
        0.48324643494561315,
        0.4402249907143414,
        0.455316458363086,
        0.4490179670974612,
        0.49472187319770455,
        0.5128956642001867,
        0.44478171318769455,
        0.4331017918884754,
        0.3881707708351314,
        0.44862460251897573,
        0.45915614627301693,
        0.4547116095200181,
        0.4859930817037821,
        0.47394248750060797,
        0.4275895901955664,
        0.4499440533109009,
        0.46757229603827,
        0.4160618162713945,
        0.41683008521795273,
        0.42700312240049243,
        0.4539561429992318,
        0.43541147001087666,
        0.36821306589990854,
        0.4750720662996173,
        0.4020036393776536,
        0.4355887440033257,
        0.4482122487388551,
        0.4419239046983421,
        0.4516557725146413,
        0.4351324588060379,
        0.45222019823268056,
        0.45624125842005014,
        0.452748604118824,
        0.4261944913305342,
        0.40634963335469365,
        0.3815563931129873,
        0.4759303950704634,
        0.4049846502020955,
        0.4450170467607677,
        0.392032690346241,
        0.40091344295069575,
        0.4458685265854001,
        0.4230129043571651,
        0.4409728553146124
      ],
      "train_rec_loss": [
        0.40352342603728175,
        0.19841467076912522,
        0.1794549054466188,
        0.17394860833883286,
        0.16750217508524656,
        0.16455945651978254,
        0.16337631922215223,
        0.16183045553043485,
        0.15941558638587594,
        0.15928385453298688,
        0.1573463468812406,
        0.15551238600164652,
        0.16001988714560866,
        0.15810643509030342,
        0.15649017365649343,
        0.16391342971473932,
        0.15919151483103633,
        0.15748800011351705,
        0.15646426239982247,
        0.1562912566587329,
        0.15478145889937878,
        0.15508347190916538,
        0.15337867150083184,
        0.15357708977535367,
        0.15601178724318743,
        0.15620657382532954,
        0.1544546065852046,
        0.15549790253862739,
        0.15466530760750175,
        0.15349925449118018,
        0.1544295810163021,
        0.1529368101619184,
        0.15573814883828163,
        0.15324567211791873,
        0.1531814904883504,
        0.15221277670934796,
        0.1508508692495525,
        0.15178222628310323,
        0.15225972281768918,
        0.1509092473424971,
        0.15017103077843785,
        0.1516171982511878,
        0.15103636542335153,
        0.15110797435045242,
        0.14960874896496534,
        0.15640522865578532,
        0.1529887211509049,
        0.15301226917654276,
        0.15217976504936814,
        0.15030587278306484,
        0.15019092289730906,
        0.15114363376051188,
        0.15048311557620764,
        0.14929834799841046,
        0.14885286334902048,
        0.14736414002254605,
        0.14696836937218904,
        0.1468899636529386,
        0.14730011951178312,
        0.14735296973958611,
        0.15048073045909405,
        0.15323854330927134,
        0.15517012076452374,
        0.1514003984630108,
        0.14893303718417883,
        0.1474848478101194,
        0.14716318575665355,
        0.14651847817003727,
        0.14733395772054791,
        0.14807084714993834,
        0.14682982070371509,
        0.14671714417636395,
        0.14572815783321857,
        0.1484073344618082,
        0.14769676281139255,
        0.14698232617229223,
        0.14505615923553705,
        0.14501396007835865,
        0.1453761225566268,
        0.1452462892048061,
        0.14584186859428883,
        0.14523461367934942,
        0.14502311404794455,
        0.145026417914778,
        0.14540811954066157,
        0.14438849641010165,
        0.1448518605902791,
        0.1450873389840126,
        0.14456698531284928,
        0.14467073883861303,
        0.14635340590029955,
        0.14406554447486997,
        0.1444611744955182,
        0.1445175176486373,
        0.14513093465939164,
        0.14426678349263966,
        0.14499938022345304,
        0.14447021298110485,
        0.14489651657640934,
        0.14528077794238925
      ],
      "train_disc_loss": [
        0.1008966292720288,
        0.09045216816593893,
        0.16084833120112307,
        0.2422133557847701,
        0.35571336082648486,
        0.3953137340140529,
        0.4725173628976336,
        0.5716937418328598,
        0.7269548364274669,
        0.7612994477385655,
        0.844711893965723,
        0.72101645017392,
        0.6499605745193549,
        0.7847824200580362,
        0.8140328188310377,
        0.852993172564311,
        0.667189100116957,
        0.7303011621406768,
        0.6174723928561434,
        0.5910216663469328,
        0.6841723168472527,
        0.6753885365033057,
        0.6713308112812229,
        0.6027364306355594,
        0.750232247490203,
        0.653865043001133,
        0.7238640692085028,
        0.6892437602073187,
        0.6785110774944769,
        0.6198046218487434,
        0.7141209591936786,
        0.6381561789021362,
        0.6496415606816299,
        0.6202788512891857,
        0.6473040564160328,
        0.6396016432554461,
        0.6005454023688799,
        0.6272828611254226,
        0.61391069979436,
        0.5420088115351973,
        0.6801899081765441,
        0.643321149982512,
        0.6599141290353145,
        0.7270466836926062,
        0.6091777908222866,
        0.6769724820187548,
        0.6824065150140086,
        0.6157737604589784,
        0.6656581368297338,
        0.6164916321649798,
        0.6082052328129066,
        0.7034863176595536,
        0.5974573625790072,
        0.5485556479252409,
        0.6342202171726967,
        0.595546135911718,
        0.6725561280109105,
        0.586670046337531,
        0.6160326794342836,
        0.6033299857517704,
        0.6884822775027715,
        0.719314249989111,
        0.5792231776649714,
        0.5634027938867803,
        0.4784754724460072,
        0.6022795056996983,
        0.6239859245106345,
        0.6163862652902026,
        0.6773182522883872,
        0.6517432823893614,
        0.5615195377977216,
        0.6064538148930296,
        0.6436882716661785,
        0.5353089517302578,
        0.538266647788987,
        0.5600415953595075,
        0.6177999555511633,
        0.5807950220041675,
        0.44567388583527645,
        0.6596515576820821,
        0.5123235380451661,
        0.5807082588726189,
        0.6063782750279643,
        0.5937949694925919,
        0.6124953045218717,
        0.5814879339159233,
        0.6147366765653715,
        0.6223078232869739,
        0.6163632434763713,
        0.5630475088837557,
        0.519992453235318,
        0.4749816950279637,
        0.6629384464540635,
        0.5209342597227078,
        0.5997722198662814,
        0.49553181028022664,
        0.5118281266040867,
        0.6027966256951913,
        0.55623277581617,
        0.5913841576257255
      ],
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100
      ]
    }
  },
  {
    "experiment_name": "LambdaDisc_0.1",
    "config": {
      "seq_length": 100,
      "num_features": 5,
      "num_train_samples": 1000,
      "num_test_samples": 300,
      "train_anomaly_ratio": 0.05,
      "test_anomaly_ratio": 0.25,
      "d_model": 64,
      "nhead": 4,
      "num_encoder_layers": 3,
      "num_teacher_decoder_layers": 4,
      "num_student_decoder_layers": 1,
      "dim_feedforward": 256,
      "dropout": 0.1,
      "masking_ratio": 0.6,
      "masking_strategy": "patch",
      "patch_size": 10,
      "margin": 1.0,
      "lambda_disc": 0.1,
      "batch_size": 32,
      "num_epochs": 100,
      "learning_rate": 0.001,
      "weight_decay": 1e-05,
      "warmup_epochs": 10,
      "mask_last_n": 10,
      "use_discrepancy_loss": true,
      "use_teacher": true,
      "use_student": true,
      "use_masking": true,
      "random_seed": 42,
      "device": "cuda"
    },
    "metrics": {
      "sequence": {
        "roc_auc": 0.6523851851851851,
        "precision": 0.9375,
        "recall": 0.4,
        "f1_score": 0.5607476635514018,
        "optimal_threshold": 0.1161658987402916
      },
      "point": {
        "roc_auc": 0.7289765255105435,
        "precision": 0.37471655328798187,
        "recall": 0.5118079752226093,
        "f1_score": 0.43266241204385536,
        "optimal_threshold": 0.11053019762039185
      },
      "combined": {
        "roc_auc": 0.6857432060679356,
        "precision": 0.6923894968003295,
        "recall": 0.44869601127869285,
        "f1_score": 0.5049623688116718,
        "seq_weight": 0.564467461451303,
        "point_weight": 0.435532538548697
      }
    },
    "history": {
      "train_loss": [
        0.4114297144114971,
        0.21224382566288114,
        0.19951574970036745,
        0.19895852264016867,
        0.20493962662294507,
        0.20561414398252964,
        0.21020255843177438,
        0.2179051493294537,
        0.22879072930663824,
        0.22978136455640197,
        0.23806914663873613,
        0.22246368834748864,
        0.22204764792695642,
        0.221049215644598,
        0.21449579950422049,
        0.21588294813409448,
        0.19580038217827678,
        0.20772793889045715,
        0.1867836662568152,
        0.18681345880031586,
        0.19123428664170206,
        0.18376877554692328,
        0.17301841569133103,
        0.15938334167003632,
        0.16623864648863673,
        0.15135327260941267,
        0.1523104147054255,
        0.15231214673258364,
        0.13763815467245877,
        0.13510575448162854,
        0.1326273123268038,
        0.1285158796235919,
        0.12144936877302825,
        0.11885619349777699,
        0.12329742626752704,
        0.11652887635864317,
        0.11302959232125431,
        0.11239084671251476,
        0.11375777807552367,
        0.09284295386169106,
        0.10541446576826274,
        0.10457051976118237,
        0.10611494421027601,
        0.12397362000774592,
        0.09964255336672068,
        0.09996606200002134,
        0.10306517605204135,
        0.10106317210011184,
        0.098985759424977,
        0.09704537107609212,
        0.10042453417554498,
        0.10122706205584109,
        0.08690590795595199,
        0.09429303940851241,
        0.09811664139851928,
        0.08996329247020185,
        0.1028156119864434,
        0.08748300129082054,
        0.08791718422435224,
        0.0904340761480853,
        0.09631826099939644,
        0.10385005350690335,
        0.08873106527607888,
        0.08925296715460718,
        0.08251553447917104,
        0.09588154836092144,
        0.08738795924000442,
        0.0909040003316477,
        0.09275465784594417,
        0.08792420639656484,
        0.08640799834392965,
        0.09162434819154441,
        0.0898856210988015,
        0.07859068864490837,
        0.08897490834351629,
        0.08644283085595816,
        0.09218529623467475,
        0.08769044675864279,
        0.07190912554506212,
        0.09170855686534196,
        0.08480789558961987,
        0.08217253722250462,
        0.08878509607166052,
        0.08946613722946495,
        0.09061235329136252,
        0.08994596800766885,
        0.08848128677345812,
        0.09216224460396916,
        0.08612559316679835,
        0.0772827147739008,
        0.0817951017525047,
        0.07201466127298772,
        0.09363367047626525,
        0.0882612211862579,
        0.08256422798149288,
        0.08348404278513044,
        0.0794215596979484,
        0.09337588807102293,
        0.09056702780071646,
        0.0823071280028671
      ],
      "train_rec_loss": [
        0.40005417773500085,
        0.2030607066117227,
        0.183272039052099,
        0.17460434045642614,
        0.16926892986521125,
        0.16600245237350464,
        0.16287434054538608,
        0.1606563087552786,
        0.15606052009388804,
        0.1537319333292544,
        0.1579921639058739,
        0.15221698908135295,
        0.1599501771852374,
        0.15244005247950554,
        0.15095936506986618,
        0.15214466722682118,
        0.1448127431795001,
        0.14154062885791063,
        0.13691314333118498,
        0.13313101674430072,
        0.1283675879240036,
        0.1256017256528139,
        0.11599914846010506,
        0.10983837209641933,
        0.102056335657835,
        0.09470973466522992,
        0.08589251944795251,
        0.08897129609249532,
        0.07598769443575293,
        0.07451760512776673,
        0.07225598592776805,
        0.06996333331335336,
        0.06531420967075974,
        0.06074146775063127,
        0.05893640290014446,
        0.06003249576315284,
        0.05592582654207945,
        0.05467567371670157,
        0.053858534432947636,
        0.051672206027433276,
        0.05216108646709472,
        0.05262205470353365,
        0.049596527009271085,
        0.05141223792452365,
        0.04915722389705479,
        0.051301765139214694,
        0.04897583893034607,
        0.04770925408229232,
        0.0461735479766503,
        0.04633072763681412,
        0.04599740158300847,
        0.046738576027564704,
        0.04538278630934656,
        0.0449884079862386,
        0.045573692419566214,
        0.04406769457273185,
        0.04468598810490221,
        0.04378303571138531,
        0.04456007352564484,
        0.04335183836519718,
        0.043887512176297605,
        0.044051282573491335,
        0.04288540920242667,
        0.04312906682025641,
        0.04176833387464285,
        0.04188155976589769,
        0.0407810437027365,
        0.04116888530552387,
        0.04192206566222012,
        0.04156391101423651,
        0.04192894999869168,
        0.041170622571371496,
        0.040654243784956634,
        0.0410356312058866,
        0.040892685297876596,
        0.04079592158086598,
        0.040550340665504336,
        0.04010065272450447,
        0.04029137163888663,
        0.04018877155613154,
        0.03997678740415722,
        0.0402126950211823,
        0.039737345185130835,
        0.0398999007884413,
        0.03989286825526506,
        0.03971533360891044,
        0.03979586553759873,
        0.04022009065374732,
        0.03933464630972594,
        0.03899088758043945,
        0.039885827573016286,
        0.038965120154898614,
        0.039759580977261066,
        0.03919537703040987,
        0.039594260859303176,
        0.03940775862429291,
        0.03905656060669571,
        0.039237324614077806,
        0.03946769062895328,
        0.03936524025630206
      ],
      "train_disc_loss": [
        0.11375540267908946,
        0.09183118888176978,
        0.16243711215793155,
        0.24354183056857437,
        0.3567069556156639,
        0.39611690476885997,
        0.4732821687939577,
        0.572488393081585,
        0.7273020628781524,
        0.7604943066835403,
        0.8007698146393523,
        0.7024669672246091,
        0.620974684949033,
        0.6860916398873087,
        0.6353643215843476,
        0.6373828033392783,
        0.5098763805581257,
        0.6618731049238704,
        0.49870522471610457,
        0.5368244060664438,
        0.6286669709952548,
        0.581670490821125,
        0.5701926691981498,
        0.49544967914698645,
        0.6418230866838712,
        0.5664353806641884,
        0.6641789411078207,
        0.6334085055277683,
        0.6165046042879112,
        0.6058814847492613,
        0.6037132611381821,
        0.5855254366178997,
        0.56135158642428,
        0.5811472377972677,
        0.6436102248262614,
        0.5649638040340506,
        0.5710376464994624,
        0.5771517224493437,
        0.5989924280438572,
        0.41170746757416055,
        0.5325337930698879,
        0.5194846451631747,
        0.5651841681101359,
        0.7256138169905171,
        0.5048532754881307,
        0.4866429691319354,
        0.540893369470723,
        0.5335391753469594,
        0.5281221040640958,
        0.5071464127977379,
        0.5442713150405325,
        0.5448848523083143,
        0.41523120435886085,
        0.4930462916963734,
        0.5254294711048715,
        0.458955975191202,
        0.5812962373602204,
        0.436999648809433,
        0.4335711066960357,
        0.4708223728230223,
        0.5243074788013473,
        0.5979877142235637,
        0.4584565485129133,
        0.4612390013062395,
        0.4074720008065924,
        0.5399998869979754,
        0.4660691409371793,
        0.49735114676877856,
        0.5083259185194038,
        0.46360295050544664,
        0.4447904707631096,
        0.5045372480526567,
        0.4923137699952349,
        0.37555057293502614,
        0.48082222894299775,
        0.4564690727274865,
        0.5163495412562042,
        0.47589793003862724,
        0.31617754214676097,
        0.5151978392968886,
        0.44831107108620927,
        0.4195984122925438,
        0.4904774953611195,
        0.4956623516045511,
        0.5071948449476622,
        0.5023063411936164,
        0.48685420549008995,
        0.5194215302472003,
        0.46790945692919195,
        0.3829182735644281,
        0.41909273609053344,
        0.33049540914362296,
        0.5387408832320943,
        0.49065843562129885,
        0.4296996708144434,
        0.44076284050242975,
        0.40364998241420835,
        0.5413856189697981,
        0.5109933579806238,
        0.42941886477638036
      ],
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100
      ]
    }
  },
  {
    "experiment_name": "LambdaDisc_1.0",
    "config": {
      "seq_length": 100,
      "num_features": 5,
      "num_train_samples": 1000,
      "num_test_samples": 300,
      "train_anomaly_ratio": 0.05,
      "test_anomaly_ratio": 0.25,
      "d_model": 64,
      "nhead": 4,
      "num_encoder_layers": 3,
      "num_teacher_decoder_layers": 4,
      "num_student_decoder_layers": 1,
      "dim_feedforward": 256,
      "dropout": 0.1,
      "masking_ratio": 0.6,
      "masking_strategy": "patch",
      "patch_size": 10,
      "margin": 1.0,
      "lambda_disc": 1.0,
      "batch_size": 32,
      "num_epochs": 100,
      "learning_rate": 0.001,
      "weight_decay": 1e-05,
      "warmup_epochs": 10,
      "mask_last_n": 10,
      "use_discrepancy_loss": true,
      "use_teacher": true,
      "use_student": true,
      "use_masking": true,
      "random_seed": 42,
      "device": "cuda"
    },
    "metrics": {
      "sequence": {
        "roc_auc": 0.7008592592592592,
        "precision": 0.8529411764705882,
        "recall": 0.38666666666666666,
        "f1_score": 0.5321100917431193,
        "optimal_threshold": 0.002675396390259266
      },
      "point": {
        "roc_auc": 0.6152527352784093,
        "precision": 0.30782385634886705,
        "recall": 0.2787456445993031,
        "f1_score": 0.2925639983746445,
        "optimal_threshold": 0.02234860695898533
      },
      "combined": {
        "roc_auc": 0.6704892170293452,
        "precision": 0.6595536253529002,
        "recall": 0.34838026225180574,
        "f1_score": 0.44712795915192904,
        "seq_weight": 0.6452368252131381,
        "point_weight": 0.3547631747868618
      }
    },
    "history": {
      "train_loss": [
        0.49658352974802256,
        0.28772763442248106,
        0.33978443732485175,
        0.4137646509334445,
        0.5233369865454733,
        0.5599462878890336,
        0.6346244169399142,
        0.7319457628764212,
        0.8846248220652342,
        0.9600820550695062,
        1.009529325645417,
        0.8813137616962194,
        0.8796531176194549,
        0.9406858459115028,
        0.9706571195274591,
        1.0025331708602607,
        0.8799344836734235,
        1.00327341677621,
        0.9090099069289863,
        0.8782213982194662,
        1.002277531195432,
        0.9692825451493263,
        0.968148781452328,
        0.9384225532412529,
        0.9685272667557001,
        0.9668502393178642,
        0.9988493919372559,
        0.9417291600257158,
        0.9073404869996011,
        0.887942680157721,
        0.9699460566043854,
        0.9064803794026375,
        0.8742978358641267,
        0.9055154561065137,
        0.9682111823931336,
        0.9363635662011802,
        0.9044073317199945,
        0.967860949691385,
        0.937903412617743,
        0.8485370529815555,
        0.9662760100327432,
        0.8288845838978887,
        0.9894108767621219,
        1.000346913933754,
        0.9875017437152565,
        0.9317364795133471,
        0.7640461749397218,
        0.7713691433891654,
        0.7267326465807855,
        0.7596903317607939,
        0.7424088665284216,
        0.7039321097545326,
        0.6372410040348768,
        0.6589706586673856,
        0.7560381209477782,
        0.7278732783161104,
        0.8108734788838774,
        0.6442884644493461,
        0.7171828430145979,
        0.6802294226363301,
        0.7439253223128617,
        0.8187702866271138,
        0.6751342336647213,
        0.6782235479913652,
        0.6180306877940893,
        0.7195923286490142,
        0.7661546524614096,
        0.7748838476836681,
        0.7637345008552074,
        0.7510598315857351,
        0.6762189315631986,
        0.7556660417467356,
        0.7854510182514787,
        0.6602916321717203,
        0.7321077650412917,
        0.7143570631742477,
        0.7908693980425596,
        0.7519481927156448,
        0.5183735410682857,
        0.8106386712752283,
        0.7097526332363486,
        0.7194843385368586,
        0.7666144585236907,
        0.8580784634687006,
        0.757752503734082,
        0.7801309442147613,
        0.7926108073443174,
        0.8380920528434217,
        0.7262584730051458,
        0.6719599957577884,
        0.6765011288225651,
        0.6416857629083097,
        0.7986896797083318,
        0.7290150257758796,
        0.7809842522256076,
        0.6980809988453984,
        0.6475371071137488,
        0.7958504878915846,
        0.7286255746148527,
        0.7025977913290262
      ],
      "train_rec_loss": [
        0.4047642685472965,
        0.19797838712111115,
        0.17986102122813463,
        0.1722727552987635,
        0.16816977504640818,
        0.1651168866083026,
        0.16235094564035535,
        0.16043918346986175,
        0.1581772370263934,
        0.2270640474744141,
        0.16383240185678005,
        0.15961119858548045,
        0.15877583902329206,
        0.1573931467719376,
        0.156914038117975,
        0.15778996422886848,
        0.1589931338094175,
        0.15857004467397928,
        0.1576574919745326,
        0.1580942585133016,
        0.15780962584540248,
        0.15592476772144437,
        0.15480598341673613,
        0.1547322585247457,
        0.15463983407244086,
        0.15335624478757381,
        0.15431964211165905,
        0.16050367802381516,
        0.1569004156626761,
        0.15832675341516733,
        0.15612809360027313,
        0.15524960216134787,
        0.1542232409119606,
        0.15443187579512596,
        0.15505347587168217,
        0.15434203715994954,
        0.15353141073137522,
        0.15462784469127655,
        0.15502769872546196,
        0.15578702557832003,
        0.15372130181640387,
        0.15965830069035292,
        0.15536721982061863,
        0.15607562568038702,
        0.15370152425020933,
        0.153532033553347,
        0.15465849451720715,
        0.15591419488191605,
        0.15383142651990056,
        0.1538844434544444,
        0.15322082862257957,
        0.15284659108147025,
        0.15456274477764964,
        0.15250797802582383,
        0.15393678890541196,
        0.15275964653119445,
        0.1534637683071196,
        0.15296660736203194,
        0.15372184151783586,
        0.15322000393643975,
        0.15203437861055136,
        0.15387005591765046,
        0.15239897929131985,
        0.15225568413734436,
        0.15259616170078516,
        0.15179482055827975,
        0.15155058400705457,
        0.15219857217743993,
        0.15123237390071154,
        0.15170824714004993,
        0.15179269574582577,
        0.14984351163730025,
        0.1511916103772819,
        0.15077835880219936,
        0.15016787126660347,
        0.1502273785881698,
        0.15007399814203382,
        0.15035029407590628,
        0.14788953261449933,
        0.14784024842083454,
        0.14897844661027193,
        0.14748269319534302,
        0.14678468089550734,
        0.14880877221003175,
        0.14718713983893394,
        0.14742024894803762,
        0.14724780106917024,
        0.1474022287875414,
        0.14679122669622302,
        0.14508440950885415,
        0.1483623436652124,
        0.14573300862684846,
        0.14649521047249436,
        0.14640968153253198,
        0.14622629340738058,
        0.1446783288847655,
        0.14691203692927957,
        0.1475746645592153,
        0.1466075712814927,
        0.14613981125876307
      ],
      "train_disc_loss": [
        0.09181926271412522,
        0.08974924645735882,
        0.1599234176974278,
        0.24149189665331505,
        0.3551672074536327,
        0.39482939649315085,
        0.4722734712267993,
        0.5715065826370846,
        0.7264475838310318,
        0.7330179996206425,
        0.8456969172984827,
        0.7217025670397561,
        0.7208772855228744,
        0.7832926989212865,
        0.8137430792994564,
        0.8447432079847204,
        0.7209413439850323,
        0.8447033751290292,
        0.7513524182868423,
        0.7201271365047432,
        0.8444679108652053,
        0.8133577883418184,
        0.8133428015862592,
        0.7836902983253822,
        0.8138874313153792,
        0.8134939887386281,
        0.8445297415164532,
        0.7812254872842459,
        0.7504400743782753,
        0.7296159149555024,
        0.813817964066402,
        0.7512307777797105,
        0.7200745966256363,
        0.7510835753928404,
        0.8131577030799235,
        0.7820215261453995,
        0.7508759066986386,
        0.8132331080269068,
        0.782875725577469,
        0.6927500314632198,
        0.8125547081581317,
        0.6692262794458657,
        0.8340436533180764,
        0.844271278285305,
        0.8338002222881187,
        0.7782044502600911,
        0.6093876910817926,
        0.6154549560451414,
        0.5729012214142131,
        0.6058058926719241,
        0.5891880388662685,
        0.551085516664898,
        0.4826782658637967,
        0.5064626714301994,
        0.6021013256977312,
        0.5751136316466727,
        0.6574097150878515,
        0.49132185855705757,
        0.5634610023334972,
        0.5270094141196751,
        0.5918909419779084,
        0.6649002347039641,
        0.5227352555484686,
        0.5259678644215455,
        0.46543452861442347,
        0.5677975114740548,
        0.6146040675594122,
        0.6226852722102194,
        0.6125021212174033,
        0.5993515868940449,
        0.5244262352061924,
        0.6058225265951478,
        0.6342594082343567,
        0.5095132749884215,
        0.5819399013998918,
        0.5641296813664667,
        0.6407953991147224,
        0.6015979102594429,
        0.370484008690255,
        0.6627984120787005,
        0.5607741861385875,
        0.572001642347459,
        0.6198297757073306,
        0.7092696907784557,
        0.6105653661652468,
        0.6327106986063882,
        0.6453630086907651,
        0.6906898225352052,
        0.5794672526681097,
        0.5268755859215162,
        0.5281387833019835,
        0.4959527474202332,
        0.6521944634878309,
        0.5826053467462771,
        0.634757967585756,
        0.5534026628010906,
        0.5006250656224438,
        0.6482758296333486,
        0.5820180116061238,
        0.5564579778292682
      ],
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100
      ]
    }
  },
  {
    "experiment_name": "Margin_0.5",
    "config": {
      "seq_length": 100,
      "num_features": 5,
      "num_train_samples": 1000,
      "num_test_samples": 300,
      "train_anomaly_ratio": 0.05,
      "test_anomaly_ratio": 0.25,
      "d_model": 64,
      "nhead": 4,
      "num_encoder_layers": 3,
      "num_teacher_decoder_layers": 4,
      "num_student_decoder_layers": 1,
      "dim_feedforward": 256,
      "dropout": 0.1,
      "masking_ratio": 0.6,
      "masking_strategy": "patch",
      "patch_size": 10,
      "margin": 0.5,
      "lambda_disc": 0.5,
      "batch_size": 32,
      "num_epochs": 100,
      "learning_rate": 0.001,
      "weight_decay": 1e-05,
      "warmup_epochs": 10,
      "mask_last_n": 10,
      "use_discrepancy_loss": true,
      "use_teacher": true,
      "use_student": true,
      "use_masking": true,
      "random_seed": 42,
      "device": "cuda"
    },
    "metrics": {
      "sequence": {
        "roc_auc": 0.7366518518518518,
        "precision": 0.8409090909090909,
        "recall": 0.49333333333333335,
        "f1_score": 0.6218487394957983,
        "optimal_threshold": 0.07125953584909439
      },
      "point": {
        "roc_auc": 0.7553751680837689,
        "precision": 0.33458646616541354,
        "recall": 0.5857530003871467,
        "f1_score": 0.4258972554539057,
        "optimal_threshold": 0.05783909559249878
      },
      "combined": {
        "roc_auc": 0.7442626745460983,
        "precision": 0.63509449720797,
        "recall": 0.530900914348112,
        "f1_score": 0.5421966103940612,
        "seq_weight": 0.5935109678235033,
        "point_weight": 0.4064890321764966
      }
    },
    "history": {
      "train_loss": [
        0.45069260662421584,
        0.2272553234361112,
        0.22466461639851332,
        0.23579688370227814,
        0.2590298894792795,
        0.2654785313643515,
        0.28177347872406244,
        0.30388288712128997,
        0.3387000132352114,
        0.3299292125739157,
        0.3678256580606103,
        0.2965431925840676,
        0.2942375913262367,
        0.2951389108784497,
        0.3105882848612964,
        0.30537102557718754,
        0.28023019013926387,
        0.32040476985275745,
        0.2675083070062101,
        0.2810446619987488,
        0.2878571073524654,
        0.30410716217011213,
        0.2699266450945288,
        0.2424198817461729,
        0.2652954568620771,
        0.27158601046539843,
        0.2818090892396867,
        0.28536881622858346,
        0.262768286280334,
        0.2558181833010167,
        0.24468429549597204,
        0.23021688498556614,
        0.24334320588968694,
        0.2270620868075639,
        0.22004390135407448,
        0.21710491180419922,
        0.1998763473238796,
        0.2095205639488995,
        0.21936574182473123,
        0.18544370727613568,
        0.2235000126529485,
        0.21057063690386713,
        0.21530609019100666,
        0.21192783513106406,
        0.17302047880366445,
        0.17959488928318024,
        0.18349154200404882,
        0.1857340526767075,
        0.16909003630280495,
        0.17628618201706558,
        0.18754109903238714,
        0.17153795913327485,
        0.15352643968071789,
        0.15952290873974562,
        0.17097962112165987,
        0.1550208864500746,
        0.19123696419410408,
        0.15687734307721257,
        0.155063537764363,
        0.16127507749479264,
        0.1727648280793801,
        0.1857809063512832,
        0.13706683355849236,
        0.15461064036935568,
        0.1423712125979364,
        0.17540103592909873,
        0.15159177780151367,
        0.16022343502845615,
        0.16887735028285533,
        0.1666972702369094,
        0.14799219905398786,
        0.15362923429347575,
        0.16894183319527656,
        0.13747513806447387,
        0.14555555500555784,
        0.14544063818175346,
        0.16267386579420418,
        0.15786839241627604,
        0.1225512851960957,
        0.15710149565711617,
        0.1492511531105265,
        0.13540412730071694,
        0.14630652428604662,
        0.16174554987810552,
        0.1571133693214506,
        0.1537371960002929,
        0.16160472249612212,
        0.1634650183841586,
        0.14656121341977268,
        0.13243867305573076,
        0.13519793062005192,
        0.11984979140106589,
        0.15671177837066352,
        0.1487166027072817,
        0.1443324851570651,
        0.13983006624039263,
        0.1400374243967235,
        0.16713510628324002,
        0.16121632675640285,
        0.14260768645908684
      ],
      "train_rec_loss": [
        0.40030571911484003,
        0.20068207057192922,
        0.18160629412159324,
        0.17318867426365614,
        0.16860390873625875,
        0.16544813616201282,
        0.16259146062657237,
        0.16008594213053584,
        0.15646124351769686,
        0.1611621892079711,
        0.17035519517958164,
        0.15708496561273932,
        0.15439113415777683,
        0.150489462306723,
        0.1495754662901163,
        0.14943002699874341,
        0.14739205641672015,
        0.14563535852357745,
        0.14335310459136963,
        0.141343665542081,
        0.1350902528502047,
        0.14634904731065035,
        0.13110655918717384,
        0.125027593690902,
        0.12205942953005433,
        0.12467706645838916,
        0.1176056347321719,
        0.1144479219801724,
        0.11060923361219466,
        0.10383086767978966,
        0.09219908341765404,
        0.08687969134189188,
        0.0928321999963373,
        0.08287327829748392,
        0.07769329007714987,
        0.07795343757607043,
        0.07530061423312873,
        0.07365879870485514,
        0.07258423662278801,
        0.06726759148295969,
        0.06824044114910066,
        0.06789959140587598,
        0.06938241946045309,
        0.0638819569721818,
        0.05773078976199031,
        0.05857887654565275,
        0.05725096515379846,
        0.05696790537331253,
        0.05609354539774358,
        0.056025592843070626,
        0.056763047468848526,
        0.055895473109558225,
        0.05441866780165583,
        0.05209774663671851,
        0.05068403703626245,
        0.049803531845100224,
        0.04961923451628536,
        0.04988691094331443,
        0.050242648692801595,
        0.049573073047213256,
        0.04751848743762821,
        0.04800184606574476,
        0.04756518185604364,
        0.04887416632845998,
        0.04867926461156458,
        0.04832422535400838,
        0.04619422880932689,
        0.04687444225419313,
        0.04674692975822836,
        0.04607381334062666,
        0.04635638708714396,
        0.04484008462168276,
        0.04508272651582956,
        0.04548034456092864,
        0.04519916919525713,
        0.045014562318101525,
        0.04470384796150029,
        0.044118365505710244,
        0.045079155126586556,
        0.044066514004953206,
        0.04420618957374245,
        0.04473993740975857,
        0.04396996891591698,
        0.04402015288360417,
        0.044839767389930785,
        0.044162449543364346,
        0.043619149015285075,
        0.04400214157067239,
        0.043820383260026574,
        0.04313386103603989,
        0.04400663066189736,
        0.04351434751879424,
        0.04399268014822155,
        0.0433714835671708,
        0.04455846583005041,
        0.043529781280085444,
        0.043134847772307694,
        0.04335299308877438,
        0.04317067051306367,
        0.04375470499508083
      ],
      "train_disc_loss": [
        0.10077377123525366,
        0.053146506019402295,
        0.08611664469935931,
        0.12521641689818352,
        0.1808519587793853,
        0.20006079874292482,
        0.23836403427412733,
        0.2875938845536439,
        0.36447753668471705,
        0.33753404414164834,
        0.3949409210763406,
        0.2789164491405245,
        0.2796929158794228,
        0.28929890115978196,
        0.3220256339991465,
        0.3118819988449104,
        0.2656762638071086,
        0.3495388191367965,
        0.2483104011917021,
        0.2794019905559253,
        0.30553370411507785,
        0.31551622826373205,
        0.2776401694281958,
        0.23478457680903375,
        0.2864720559446141,
        0.29381789002218284,
        0.3284069078217726,
        0.34184179015574045,
        0.3043181082466617,
        0.30397463077679276,
        0.3049704286677297,
        0.2866743929916993,
        0.30102201155386865,
        0.2883776210946962,
        0.28470122400904074,
        0.27830294863088056,
        0.24915146839339286,
        0.27172353345667943,
        0.2935630156425759,
        0.23635222972370684,
        0.31051914603449404,
        0.2853420914034359,
        0.29184734320733696,
        0.29609175462974235,
        0.23057937936391681,
        0.24203202448552474,
        0.25248115381691605,
        0.25753229594556615,
        0.2259929795982316,
        0.24052117834798992,
        0.2615561056882143,
        0.23128497158177197,
        0.19821554276859388,
        0.21485032327473164,
        0.24059116595890373,
        0.2104347111308016,
        0.28323546407045797,
        0.21398086455883458,
        0.20964177744463086,
        0.2234040104667656,
        0.2504926811088808,
        0.2755581231904216,
        0.17900330253178254,
        0.2114729494205676,
        0.18738389445934445,
        0.2541536178905517,
        0.21079509938135743,
        0.22669798583956435,
        0.24426084104925394,
        0.241246915073134,
        0.20327162381727248,
        0.21757830161368474,
        0.24771820957539603,
        0.1839895875309594,
        0.20071277202805504,
        0.20085215097060427,
        0.2359400353161618,
        0.22750005318084732,
        0.15494425810175017,
        0.2260699617327191,
        0.21008992922725156,
        0.18132837861776352,
        0.20467311015818268,
        0.23545079084578902,
        0.2245472037466243,
        0.21914949268102646,
        0.23597114806761965,
        0.23892575380159542,
        0.2054816622112412,
        0.1786096264841035,
        0.18238259881036356,
        0.15267088630935177,
        0.22543819434940815,
        0.21069023705786094,
        0.19954803778091446,
        0.19260056933853775,
        0.19380515691591427,
        0.24756422347854823,
        0.2360913116717711,
        0.19770596170565113
      ],
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100
      ]
    }
  },
  {
    "experiment_name": "Margin_2.0",
    "config": {
      "seq_length": 100,
      "num_features": 5,
      "num_train_samples": 1000,
      "num_test_samples": 300,
      "train_anomaly_ratio": 0.05,
      "test_anomaly_ratio": 0.25,
      "d_model": 64,
      "nhead": 4,
      "num_encoder_layers": 3,
      "num_teacher_decoder_layers": 4,
      "num_student_decoder_layers": 1,
      "dim_feedforward": 256,
      "dropout": 0.1,
      "masking_ratio": 0.6,
      "masking_strategy": "patch",
      "patch_size": 10,
      "margin": 2.0,
      "lambda_disc": 0.5,
      "batch_size": 32,
      "num_epochs": 100,
      "learning_rate": 0.001,
      "weight_decay": 1e-05,
      "warmup_epochs": 10,
      "mask_last_n": 10,
      "use_discrepancy_loss": true,
      "use_teacher": true,
      "use_student": true,
      "use_masking": true,
      "random_seed": 42,
      "device": "cuda"
    },
    "metrics": {
      "sequence": {
        "roc_auc": 0.6930962962962962,
        "precision": 0.868421052631579,
        "recall": 0.44,
        "f1_score": 0.584070796460177,
        "optimal_threshold": 0.081331267952919
      },
      "point": {
        "roc_auc": 0.7482606815084349,
        "precision": 0.4274292742927429,
        "recall": 0.538133952768099,
        "f1_score": 0.47643530419880037,
        "optimal_threshold": 0.11405106633901596
      },
      "combined": {
        "roc_auc": 0.717879049203756,
        "precision": 0.6703042743014225,
        "recall": 0.48408695019316506,
        "f1_score": 0.5357152533225455,
        "seq_weight": 0.5507472291741151,
        "point_weight": 0.4492527708258849
      }
    },
    "history": {
      "train_loss": [
        0.45069260662421584,
        0.28350532287731767,
        0.33716461807489395,
        0.4115781360305846,
        0.5215298887342215,
        0.5584472888149321,
        0.6333359954878688,
        0.7304453742690384,
        0.8824500171467662,
        0.8637343980371952,
        0.9409039574675262,
        0.8159226956777275,
        0.8787102452479303,
        0.9288248000666499,
        0.859970232937485,
        0.8056758996099234,
        0.7449045679531991,
        0.9374750056304038,
        0.6501085967756808,
        0.715151296928525,
        0.7720672311261296,
        0.8048765156418085,
        0.8170271408744156,
        0.692143193911761,
        0.7692530681379139,
        0.718363500200212,
        0.7993446588516235,
        0.7473182000685483,
        0.682591606862843,
        0.7291644467040896,
        0.758859338471666,
        0.692249059677124,
        0.7272197010461241,
        0.6516829994507134,
        0.697914837859571,
        0.7013531210832298,
        0.6601124498993158,
        0.7171127807814628,
        0.6981270590331405,
        0.5462523207534105,
        0.6842676713131368,
        0.7047415035776794,
        0.7319132422562689,
        0.7824524864554405,
        0.6652159539517015,
        0.6531319592613727,
        0.6138052633032203,
        0.6542358379811049,
        0.567986166337505,
        0.5455487214494497,
        0.5860680935438722,
        0.5338170379400253,
        0.485256816027686,
        0.5469709248282015,
        0.5901296541560441,
        0.5285767010645941,
        0.6055267438059673,
        0.44822788215242326,
        0.48582287423778325,
        0.5183383162366226,
        0.5582749504828826,
        0.6444577755173668,
        0.4799952602479607,
        0.48341862054076046,
        0.4598334503825754,
        0.5398762522963807,
        0.47060496313497424,
        0.5917220801347867,
        0.5249747936613858,
        0.5598395448178053,
        0.4495903303613886,
        0.5394014607882127,
        0.5683492999523878,
        0.45351871685124934,
        0.5084146808367223,
        0.48028097150381655,
        0.5191167684970424,
        0.48741779278498143,
        0.35063551156781614,
        0.5617021321086213,
        0.49696706677787006,
        0.45078995602671057,
        0.5465807399014011,
        0.5439348735380918,
        0.513141764793545,
        0.5397852991009131,
        0.5781416256213561,
        0.5454220357351005,
        0.5144047694047913,
        0.4008129194844514,
        0.47797652147710323,
        0.37671201408375055,
        0.582074869889766,
        0.5021554559934884,
        0.5026717161526904,
        0.47927327372599393,
        0.4506055135279894,
        0.5471575122792274,
        0.5384299966972321,
        0.46064230205956846
      ],
      "train_rec_loss": [
        0.40030571911484003,
        0.20068207057192922,
        0.18160629412159324,
        0.17318867426365614,
        0.16860390873625875,
        0.16544813616201282,
        0.16259146062657237,
        0.16008594213053584,
        0.15646124351769686,
        0.1667265580035746,
        0.17656927602365613,
        0.16083623096346855,
        0.15854696743190289,
        0.15683635976165533,
        0.15731492778286338,
        0.15536676859483123,
        0.15596096497029066,
        0.1640218966640532,
        0.1549651506356895,
        0.15207509323954582,
        0.15083629032596946,
        0.1523691094480455,
        0.14767532516270876,
        0.14935740921646357,
        0.15000702254474163,
        0.14373382600024343,
        0.1409054573159665,
        0.13878066674806178,
        0.133666951674968,
        0.13096821401268244,
        0.13028726377524436,
        0.12652508914470673,
        0.121712930733338,
        0.1190375778824091,
        0.11502022296190262,
        0.1097592362202704,
        0.10170607850886881,
        0.10279588960111141,
        0.09713113470934331,
        0.09040387300774455,
        0.08800946827977896,
        0.09100545244291425,
        0.09127614949829876,
        0.08533252752386034,
        0.08986514573916793,
        0.08519035042263567,
        0.07294756814371794,
        0.07461178512312472,
        0.06947717315051705,
        0.06438974663615227,
        0.06388752779457718,
        0.06551988516002893,
        0.06347467168234289,
        0.0614273794926703,
        0.058205697569064796,
        0.055700249737128615,
        0.0561807700432837,
        0.055151403532363474,
        0.05541830603033304,
        0.053178444504737854,
        0.05391749821137637,
        0.053251167526468635,
        0.05208942573517561,
        0.05195571715012193,
        0.05235359084326774,
        0.05207462527323514,
        0.0504660252481699,
        0.05012829473707825,
        0.05058558168821037,
        0.05019011511467397,
        0.050613004132173955,
        0.049136701971292496,
        0.048410146846435964,
        0.04851183225400746,
        0.0482899941271171,
        0.04933866870123893,
        0.04820281488355249,
        0.04712184006348252,
        0.04716668976470828,
        0.047142672003246844,
        0.04742747964337468,
        0.047017792938277125,
        0.046525642508640885,
        0.04677832475863397,
        0.04709241888485849,
        0.04678999143652618,
        0.046439408673904836,
        0.046890092082321644,
        0.04570278793107718,
        0.046690512099303305,
        0.04609103919938207,
        0.046108379727229476,
        0.04627693735528737,
        0.04636543430387974,
        0.04665301588829607,
        0.04599618737120181,
        0.04608660517260432,
        0.045326193096116185,
        0.045600468874908984,
        0.04634744266513735
      ],
      "train_disc_loss": [
        0.10077377123525366,
        0.16564650723012164,
        0.3111166445596609,
        0.47677892388310283,
        0.7058519642741885,
        0.7859983061935054,
        0.9414890687330626,
        1.1407188746816246,
        1.451977548233117,
        1.3940156878670678,
        1.5286693670786917,
        1.3101729178742971,
        1.4403265529253986,
        1.5439768670185003,
        1.4053106198844034,
        1.3006182666576933,
        1.1778872161230538,
        1.5469062279444188,
        0.9902869023208041,
        1.1261524119472597,
        1.2424618786899373,
        1.3050148026522947,
        1.33870362280868,
        1.0855715668585617,
        1.2384921062621288,
        1.1492593440925702,
        1.3168783777800854,
        1.2170750488294289,
        1.097849310201127,
        1.1963924716110341,
        1.2571441387699451,
        1.131447943742387,
        1.2110135458642617,
        1.065290845988784,
        1.1657892352086492,
        1.1831877498188987,
        1.1168127359705977,
        1.228633770660963,
        1.2019918462610804,
        0.9116968907765113,
        1.1925164131098427,
        1.2274721077410504,
        1.281274173699785,
        1.3942399190855213,
        1.1507016217219643,
        1.1358832162804902,
        1.0817154005053453,
        1.1592481010593474,
        0.997017985326238,
        0.9623179486370645,
        1.0443611305672675,
        0.936594299506396,
        0.8435642829863355,
        0.9710870980052277,
        1.063847907294985,
        0.9457529154606164,
        1.0986919534625486,
        0.7861529571237043,
        0.8608091314672492,
        0.9303197383997031,
        1.0087148945312947,
        1.182413229777012,
        0.8558116731583141,
        0.8629257921129465,
        0.8149597184965387,
        0.9756032568984665,
        0.8402778690797277,
        1.083187572658062,
        0.9487784235971048,
        1.0192988605122082,
        0.7979546518181451,
        0.9805295148980804,
        1.0398783082491718,
        0.8100137771689333,
        0.9202493744087406,
        0.8618845898890868,
        0.9418279145029373,
        0.8805918931029737,
        0.6069376479135826,
        1.0291189243434928,
        0.8990791674586944,
        0.8075443272828124,
        1.0001102064270526,
        0.9943131184554659,
        0.9320986862876453,
        0.98599062114954,
        1.0634044288890436,
        0.9970638949307613,
        0.9374039639951661,
        0.7082448077853769,
        0.8637709708418697,
        0.6612072639982216,
        1.0715958598884754,
        0.9115800365107134,
        0.9120373943005688,
        0.8665541742229834,
        0.8090378115302883,
        1.003662632778287,
        0.9856590493000112,
        0.8285897225141525
      ],
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100
      ]
    }
  },
  {
    "experiment_name": "DModel_32",
    "config": {
      "seq_length": 100,
      "num_features": 5,
      "num_train_samples": 1000,
      "num_test_samples": 300,
      "train_anomaly_ratio": 0.05,
      "test_anomaly_ratio": 0.25,
      "d_model": 32,
      "nhead": 4,
      "num_encoder_layers": 3,
      "num_teacher_decoder_layers": 4,
      "num_student_decoder_layers": 1,
      "dim_feedforward": 256,
      "dropout": 0.1,
      "masking_ratio": 0.6,
      "masking_strategy": "patch",
      "patch_size": 10,
      "margin": 1.0,
      "lambda_disc": 0.5,
      "batch_size": 32,
      "num_epochs": 100,
      "learning_rate": 0.001,
      "weight_decay": 1e-05,
      "warmup_epochs": 10,
      "mask_last_n": 10,
      "use_discrepancy_loss": true,
      "use_teacher": true,
      "use_student": true,
      "use_masking": true,
      "random_seed": 42,
      "device": "cuda"
    },
    "metrics": {
      "sequence": {
        "roc_auc": 0.6762074074074074,
        "precision": 0.8421052631578947,
        "recall": 0.4266666666666667,
        "f1_score": 0.5663716814159292,
        "optimal_threshold": 0.0928373858332634
      },
      "point": {
        "roc_auc": 0.7400841643460385,
        "precision": 0.3782866836301951,
        "recall": 0.5180023228803716,
        "f1_score": 0.4372549019607843,
        "optimal_threshold": 0.09598742425441742
      },
      "combined": {
        "roc_auc": 0.704036906501385,
        "precision": 0.6400311542431746,
        "recall": 0.4664593186995364,
        "f1_score": 0.5101187426464104,
        "seq_weight": 0.5643251093552794,
        "point_weight": 0.4356748906447207
      }
    },
    "history": {
      "train_loss": [
        0.6657918430864811,
        0.2608034717850387,
        0.27960422495380044,
        0.29627562360838056,
        0.3101111091673374,
        0.3629946899600327,
        0.41869180044159293,
        0.4925654651597142,
        0.48462760308757424,
        0.5101436260156333,
        0.5602967492304742,
        0.5414557363837957,
        0.5694317021407187,
        0.5674791638739407,
        0.5500762853771448,
        0.518070902209729,
        0.5310445646755397,
        0.5145717477425933,
        0.592714985832572,
        0.5347189125604928,
        0.5085744955576956,
        0.5353555618785322,
        0.5216445825062692,
        0.47657809080556035,
        0.4760780092328787,
        0.40028279880061746,
        0.46825273893773556,
        0.4377976427786052,
        0.45226459624245763,
        0.4069718341343105,
        0.4392166933976114,
        0.4160846318118274,
        0.4252471993677318,
        0.4644156703725457,
        0.46194192906841636,
        0.4075494653079659,
        0.4010027195326984,
        0.39056896488182247,
        0.38584223203361034,
        0.4084560130722821,
        0.39779224060475826,
        0.42174575524404645,
        0.41012133564800024,
        0.370989483082667,
        0.3438226303551346,
        0.35172367631457746,
        0.38466493715532124,
        0.3842761206906289,
        0.37006656639277935,
        0.361192682525143,
        0.3698912893887609,
        0.3470624298788607,
        0.3243819538038224,
        0.31842348421923816,
        0.3294767504557967,
        0.33037538337521255,
        0.3292516255751252,
        0.30771851213648915,
        0.3354983937460929,
        0.30687352758832276,
        0.3049163294490427,
        0.3570051877759397,
        0.3061994866002351,
        0.29672048334032297,
        0.30812832061201334,
        0.3308730572462082,
        0.3306790722999722,
        0.3015014517586678,
        0.30200425582006574,
        0.269640153972432,
        0.301703087054193,
        0.29614110686816275,
        0.2819768988993019,
        0.284631188493222,
        0.2871826724149287,
        0.3717843941412866,
        0.32074487907812,
        0.3217015222180635,
        0.32416148809716105,
        0.28988509299233556,
        0.3098074630834162,
        0.256479321513325,
        0.29714178619906306,
        0.35555720259435475,
        0.32042271201498806,
        0.28230617055669427,
        0.26745594572275877,
        0.2724216687493026,
        0.26923429348971695,
        0.2980586807243526,
        0.27540350367780775,
        0.2942659000400454,
        0.2877131444402039,
        0.2514388372655958,
        0.2845891562756151,
        0.32925350801087916,
        0.30526637681759894,
        0.2581570098409429,
        0.2807018584571779,
        0.2771494265180081
      ],
      "train_rec_loss": [
        0.5710078370757401,
        0.20687923720106483,
        0.1878881216980517,
        0.1742374962195754,
        0.1689112246967852,
        0.16514751920476556,
        0.1637238897383213,
        0.16318940464407206,
        0.15842883847653866,
        0.15726396907120943,
        0.15410250471904874,
        0.16727655800059438,
        0.16196359228342772,
        0.1600718623958528,
        0.1583520770072937,
        0.15751474769786,
        0.15516798058524728,
        0.1541698700748384,
        0.15495415357872844,
        0.16135830990970135,
        0.15790466079488397,
        0.15677695954218507,
        0.15468693524599075,
        0.15350866876542568,
        0.15086163999512792,
        0.1524680983275175,
        0.14940053457394242,
        0.14763834001496434,
        0.14534408692270517,
        0.14224104909226298,
        0.1394236395135522,
        0.13791044848039746,
        0.13327337172813714,
        0.12917283223941922,
        0.14121514186263084,
        0.12559542572125793,
        0.12207669531926513,
        0.11897392966784537,
        0.11840300401672721,
        0.11213798611424863,
        0.10972712095826864,
        0.10504167899489403,
        0.11365343583747745,
        0.1066092886030674,
        0.09854583465494215,
        0.09501526225358248,
        0.09343378618359566,
        0.09639245574362576,
        0.08750256872735918,
        0.08771896921098232,
        0.08621640014462173,
        0.08118963590823114,
        0.08175016101449728,
        0.08029688661918044,
        0.07941996329464018,
        0.07703266269527376,
        0.0743958808016032,
        0.07533282157965004,
        0.07356830325443298,
        0.07202410895843059,
        0.06990463414695114,
        0.07082675420679152,
        0.07043309067375958,
        0.06788032338954508,
        0.06712987436912954,
        0.06923371332231909,
        0.06771900679450482,
        0.0668682133546099,
        0.06494562572333962,
        0.06447311490774155,
        0.06540175713598728,
        0.06295265606604517,
        0.06302030000369996,
        0.06283772957976907,
        0.062223257147707045,
        0.062328012310899794,
        0.06185302627272904,
        0.06275015836581588,
        0.06193882261868566,
        0.06058903562370688,
        0.06118120765313506,
        0.061178159434348345,
        0.062179779168218374,
        0.06042065401561558,
        0.060308795305900276,
        0.06040830467827618,
        0.060903331730514765,
        0.05990609584841877,
        0.0601338924607262,
        0.06000444060191512,
        0.06003853015135974,
        0.05876250576693565,
        0.06071379943750799,
        0.05880475614685565,
        0.05955680622719228,
        0.05871888319961727,
        0.05982376646716148,
        0.060055697918869555,
        0.059871918871067464,
        0.059103268082253635
      ],
      "train_disc_loss": [
        0.18956802308093756,
        0.10784847033210099,
        0.18343220482347533,
        0.2440762569603976,
        0.28239976993063465,
        0.3956943383964244,
        0.5099358164879959,
        0.6587521172768902,
        0.6523975298332516,
        0.7057593123608967,
        0.812388479069341,
        0.7483583496650681,
        0.8149362169497181,
        0.8148146030143835,
        0.7834484040504321,
        0.7211123125453014,
        0.7517531688790768,
        0.7208037592208711,
        0.8755216692225076,
        0.7467211919138208,
        0.701339667517459,
        0.7571572122396901,
        0.7339152913191356,
        0.646138841228094,
        0.6504327375150751,
        0.4956294048606651,
        0.6377044106775429,
        0.5803186101547908,
        0.6138410140119959,
        0.5294615704769967,
        0.5995861127012176,
        0.5563483715231996,
        0.5839476529508829,
        0.6704856723372359,
        0.6414535774383694,
        0.5639080821129028,
        0.5578520513081457,
        0.5431900687981397,
        0.5348784585366957,
        0.5926360496960115,
        0.5761302384489682,
        0.6334081449895166,
        0.5929357930144761,
        0.5287603900651447,
        0.49055359058547765,
        0.5134168288495857,
        0.5824623020307627,
        0.5757673351326957,
        0.5651279988815077,
        0.5469474291312508,
        0.5673497861716896,
        0.5317455840995535,
        0.48526358214439824,
        0.4762531972373836,
        0.5001135738566518,
        0.5066854415053967,
        0.5097114818054251,
        0.4647713814047165,
        0.5238601762684993,
        0.4696988324285485,
        0.4700233932817355,
        0.572356877673883,
        0.4715327871381305,
        0.4576803157106042,
        0.48199688852764666,
        0.5232786813285202,
        0.5259201339213178,
        0.46926647383952513,
        0.4741172606591135,
        0.41033407498616725,
        0.4726026571588591,
        0.46637690695934,
        0.43791319470619783,
        0.44358691439265385,
        0.4499188361223787,
        0.6189127619145438,
        0.517783715040423,
        0.5179027249687351,
        0.5244453297345899,
        0.45859211031347513,
        0.49725251214113086,
        0.3906023211311549,
        0.469924007949885,
        0.5902730993111618,
        0.5202278375509195,
        0.4437957390327938,
        0.4131052269367501,
        0.42503114050487056,
        0.4182008014176972,
        0.476108479895629,
        0.43072994431713596,
        0.4710067816195078,
        0.45399869343964383,
        0.38526816200464964,
        0.4500647024833597,
        0.5410692484583706,
        0.4908852181979455,
        0.39620262273820117,
        0.44165988452732563,
        0.4360923224594444
      ],
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100
      ]
    }
  },
  {
    "experiment_name": "DModel_128",
    "config": {
      "seq_length": 100,
      "num_features": 5,
      "num_train_samples": 1000,
      "num_test_samples": 300,
      "train_anomaly_ratio": 0.05,
      "test_anomaly_ratio": 0.25,
      "d_model": 128,
      "nhead": 4,
      "num_encoder_layers": 3,
      "num_teacher_decoder_layers": 4,
      "num_student_decoder_layers": 1,
      "dim_feedforward": 256,
      "dropout": 0.1,
      "masking_ratio": 0.6,
      "masking_strategy": "patch",
      "patch_size": 10,
      "margin": 1.0,
      "lambda_disc": 0.5,
      "batch_size": 32,
      "num_epochs": 100,
      "learning_rate": 0.001,
      "weight_decay": 1e-05,
      "warmup_epochs": 10,
      "mask_last_n": 10,
      "use_discrepancy_loss": true,
      "use_teacher": true,
      "use_student": true,
      "use_masking": true,
      "random_seed": 42,
      "device": "cuda"
    },
    "metrics": {
      "sequence": {
        "roc_auc": 0.7321481481481482,
        "precision": 0.46938775510204084,
        "recall": 0.6133333333333333,
        "f1_score": 0.5317919075144508,
        "optimal_threshold": 0.0014233568217605352
      },
      "point": {
        "roc_auc": 0.6328472740539492,
        "precision": 0.1941611677664467,
        "recall": 0.3759194734804491,
        "f1_score": 0.25606540084388185,
        "optimal_threshold": 0.03599004074931145
      },
      "combined": {
        "roc_auc": 0.6998738798773334,
        "precision": 0.3799350005723732,
        "recall": 0.5361702803995501,
        "f1_score": 0.442176671728924,
        "seq_weight": 0.6749850536038712,
        "point_weight": 0.3250149463961288
      }
    },
    "history": {
      "train_loss": [
        0.42101492639631033,
        0.25255202129483223,
        0.26593935722485185,
        0.2916641067713499,
        0.31633861595764756,
        0.3681125259026885,
        0.40603782795369625,
        0.446848607622087,
        0.49191085901111364,
        0.5136833875440061,
        0.5517018432728946,
        0.551823413465172,
        0.5339691797271371,
        0.5171447275206447,
        0.5666326279751956,
        0.6100284005515277,
        0.588951779063791,
        0.543891828507185,
        0.4639025856740773,
        0.49917819863185287,
        0.5479988669976592,
        0.5415544402785599,
        0.5667730220593512,
        0.5187888108193874,
        0.5056767105124891,
        0.5173148796893656,
        0.49083736492320895,
        0.47839747043326497,
        0.5038198856636882,
        0.4521187753416598,
        0.4990809625014663,
        0.4545777980238199,
        0.43589286506175995,
        0.4774050894193351,
        0.5052399300038815,
        0.5185543303377926,
        0.48581225192174315,
        0.4444904481060803,
        0.4019197770394385,
        0.4537441898137331,
        0.439103317912668,
        0.4362599612213671,
        0.46003298508003354,
        0.4374608159996569,
        0.4380569430068135,
        0.48744637006893754,
        0.4488051338121295,
        0.47134077409282327,
        0.45509053859859705,
        0.40316431457176805,
        0.4851105292327702,
        0.39068510523065925,
        0.4678902728483081,
        0.4377811565063894,
        0.3943125973455608,
        0.4374279580079019,
        0.41057629929855466,
        0.4451080383732915,
        0.4135603685863316,
        0.44627016270533204,
        0.4828431592322886,
        0.4731765715405345,
        0.4864325085654855,
        0.4157084827311337,
        0.4427698696963489,
        0.4044183725491166,
        0.3999835643917322,
        0.373642829246819,
        0.40748368855565786,
        0.4500041026622057,
        0.42696975637227297,
        0.4041743855923414,
        0.41150591615587473,
        0.4440832370892167,
        0.48008409049361944,
        0.4217928077559918,
        0.4084289181046188,
        0.4538450762629509,
        0.4758393494412303,
        0.4079679250717163,
        0.4325756677426398,
        0.42469735257327557,
        0.4163954360410571,
        0.4562227325513959,
        0.4132856116630137,
        0.4400274818763137,
        0.4332846524193883,
        0.4573539807461202,
        0.46406820602715015,
        0.44356199307367206,
        0.4334157891571522,
        0.4547205436974764,
        0.43769802525639534,
        0.4520201636478305,
        0.4082380677573383,
        0.4490164536982775,
        0.412390228593722,
        0.407011401373893,
        0.43134542601183057,
        0.4546679821796715
      ],
      "train_rec_loss": [
        0.3783687329851091,
        0.2074340209364891,
        0.18799580354243517,
        0.17476816521957517,
        0.16909406566992402,
        0.16250691981986165,
        0.16395936673507094,
        0.1754113701172173,
        0.16505830036476254,
        0.1606226139701903,
        0.16023779474198818,
        0.16027955850586295,
        0.1573442416265607,
        0.1565819950774312,
        0.15913254208862782,
        0.15576231572777033,
        0.1549078058451414,
        0.1675875885412097,
        0.15705789206549525,
        0.15816992055624723,
        0.15643837628886104,
        0.17594575881958008,
        0.15908437315374613,
        0.1578891291283071,
        0.18870801012963057,
        0.1689741089940071,
        0.1569804442115128,
        0.15905616292729974,
        0.15634768968448043,
        0.15584360272623599,
        0.15649595065042377,
        0.15575086558237672,
        0.15619105333462358,
        0.16098418738693,
        0.1565959840081632,
        0.1558679868467152,
        0.15510758385062218,
        0.1556837372481823,
        0.1564147905446589,
        0.1560305217280984,
        0.15319776302203536,
        0.15367850149050355,
        0.1531115579418838,
        0.15368383238092065,
        0.15276393527165055,
        0.15110721392557025,
        0.15112554794177413,
        0.1509949821047485,
        0.14998091664165258,
        0.15266642114147544,
        0.15373365813866258,
        0.15312969079241157,
        0.15245986403897405,
        0.1532476651482284,
        0.1501320544630289,
        0.15123175829648972,
        0.1495341695845127,
        0.15107240062206984,
        0.15161278191953897,
        0.1514764353632927,
        0.15114569291472435,
        0.14997809240594506,
        0.1487859869375825,
        0.1495630033314228,
        0.15069329692050815,
        0.15060522686690092,
        0.14964785892516375,
        0.14844354009255767,
        0.15021228604018688,
        0.14952273294329643,
        0.1501109404489398,
        0.1497442051768303,
        0.15052544930949807,
        0.14925793278962374,
        0.1497776727192104,
        0.14844389026984572,
        0.1491848691366613,
        0.15092652570456266,
        0.15051975520327687,
        0.1469895145855844,
        0.14943707222118974,
        0.14879224030300975,
        0.14950108900666237,
        0.15032211551442742,
        0.1497646584175527,
        0.1483501244802028,
        0.14877520874142647,
        0.1489128298126161,
        0.14918048027902842,
        0.15021206345409155,
        0.1484804293140769,
        0.14918761979788542,
        0.14833990205079317,
        0.1484839078038931,
        0.14840898662805557,
        0.1495128977112472,
        0.1492402795702219,
        0.1495855306275189,
        0.14963782485574484,
        0.14921168284490705
      ],
      "train_disc_loss": [
        0.0852923808270134,
        0.09023599777719937,
        0.15588710628799163,
        0.23379188176477328,
        0.29448909903294407,
        0.411211209197063,
        0.4841569221462123,
        0.5428744686942082,
        0.6537051152263302,
        0.7061215502617415,
        0.7829280975420261,
        0.7830877146188868,
        0.7532498708169442,
        0.7211254722933518,
        0.8150001676403917,
        0.9085321773018222,
        0.868087949056644,
        0.7526084778364748,
        0.6136893830262125,
        0.6820165509707294,
        0.7831209840951487,
        0.731217363383621,
        0.8153772989753634,
        0.7217993569502141,
        0.6339373994269408,
        0.6966815447667614,
        0.6677138234954327,
        0.6386826205707621,
        0.6949443911726121,
        0.5925503500329796,
        0.6851700298138894,
        0.5976538639515638,
        0.5594036230177153,
        0.6328418078192044,
        0.6972878898814088,
        0.7253726875496795,
        0.6614093252137536,
        0.577613426867174,
        0.49100997929053847,
        0.5954273389434093,
        0.5718111078822403,
        0.5651629238927853,
        0.6138428438644041,
        0.5675539714793558,
        0.5705860241941991,
        0.6726783118210733,
        0.5953591623911052,
        0.6406915828556521,
        0.6102192484322586,
        0.5009957765505533,
        0.6627537375097745,
        0.47511082587152487,
        0.6308608229737729,
        0.5690669786781655,
        0.48836107514216565,
        0.5723923946934519,
        0.5220842660419294,
        0.5880712782090995,
        0.5238951697028824,
        0.5895874556154013,
        0.6633949284514529,
        0.6463969602700672,
        0.6752930496950285,
        0.5322909645765321,
        0.584153147181496,
        0.5076262854054221,
        0.5006714090559399,
        0.4503985853953054,
        0.5145428081559658,
        0.6009627378953155,
        0.5537176299840212,
        0.508860356589139,
        0.5219609383057104,
        0.5896506112767383,
        0.660612828178273,
        0.5466978408003342,
        0.5184881024979404,
        0.6058371002727654,
        0.6506391900911694,
        0.5219568180036731,
        0.5662771918723593,
        0.5518102208225173,
        0.5337886896450073,
        0.6118012343213195,
        0.5270419134467375,
        0.5833547271431598,
        0.5690188923872483,
        0.6168822942490806,
        0.6297754514234839,
        0.5866998577184859,
        0.5698707122646738,
        0.6110658504767343,
        0.5787162448250456,
        0.6070725225436036,
        0.5196581590571441,
        0.59900711584487,
        0.5262998905964196,
        0.5148517485067714,
        0.5634152040001936,
        0.610912595395348
      ],
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100
      ]
    }
  },
  {
    "experiment_name": "Masking_Patch",
    "config": {
      "seq_length": 100,
      "num_features": 5,
      "num_train_samples": 1000,
      "num_test_samples": 300,
      "train_anomaly_ratio": 0.05,
      "test_anomaly_ratio": 0.25,
      "d_model": 64,
      "nhead": 4,
      "num_encoder_layers": 3,
      "num_teacher_decoder_layers": 4,
      "num_student_decoder_layers": 1,
      "dim_feedforward": 256,
      "dropout": 0.1,
      "masking_ratio": 0.6,
      "masking_strategy": "patch",
      "patch_size": 10,
      "margin": 1.0,
      "lambda_disc": 0.5,
      "batch_size": 32,
      "num_epochs": 100,
      "learning_rate": 0.001,
      "weight_decay": 1e-05,
      "warmup_epochs": 10,
      "mask_last_n": 10,
      "use_discrepancy_loss": true,
      "use_teacher": true,
      "use_student": true,
      "use_masking": true,
      "random_seed": 42,
      "device": "cuda"
    },
    "metrics": {
      "sequence": {
        "roc_auc": 0.745362962962963,
        "precision": 0.9024390243902439,
        "recall": 0.49333333333333335,
        "f1_score": 0.6379310344827587,
        "optimal_threshold": 0.07933273166418076
      },
      "point": {
        "roc_auc": 0.7482150434653644,
        "precision": 0.3288439955106622,
        "recall": 0.5671699574138599,
        "f1_score": 0.4163114521170787,
        "optimal_threshold": 0.04990878328680992
      },
      "combined": {
        "roc_auc": 0.7464892254600655,
        "precision": 0.6759311929992327,
        "recall": 0.5224907924389011,
        "f1_score": 0.5504153335648376,
        "seq_weight": 0.6051084476212164,
        "point_weight": 0.39489155237878354
      }
    },
    "history": {
      "train_loss": [
        0.45069260662421584,
        0.24600532464683056,
        0.26216461695730686,
        0.29439063323661685,
        0.3465298870578408,
        0.3631347822956741,
        0.39896098244935274,
        0.4460703772492707,
        0.5199500108137727,
        0.5098281418904662,
        0.5608593858778477,
        0.43320857593789697,
        0.43045596638694406,
        0.4557116492651403,
        0.47581321420148015,
        0.47616616543382406,
        0.4246832481585443,
        0.50063651567325,
        0.3946522194892168,
        0.41676768800243735,
        0.4645354254171252,
        0.4448269661515951,
        0.4208258371800184,
        0.3708501972723752,
        0.41925334255211055,
        0.41202717344276607,
        0.4498936596792191,
        0.4284757920540869,
        0.40128875663504004,
        0.41250896360725164,
        0.40711268433369696,
        0.3943732383195311,
        0.37138900719583035,
        0.3637082325294614,
        0.38754785782657564,
        0.422719971742481,
        0.360121505567804,
        0.3712450307793915,
        0.37540683592669666,
        0.2822250849567354,
        0.36268930439837277,
        0.3793993969447911,
        0.38407756900414824,
        0.3988108434714377,
        0.3147265494335443,
        0.3252482063835487,
        0.3040233701467514,
        0.3282473012804985,
        0.3191215433180332,
        0.31026423117145896,
        0.3009237942751497,
        0.2863213870441541,
        0.2785054531414062,
        0.26246473274659365,
        0.30944614368490875,
        0.28926218091510236,
        0.3330000485293567,
        0.23640965961385518,
        0.2809467220213264,
        0.27085538511164486,
        0.2859509172849357,
        0.33457607065793127,
        0.25120811723172665,
        0.28418606775812805,
        0.24373586708679795,
        0.2995935339713469,
        0.2500858623534441,
        0.26324650493916124,
        0.28047673287801445,
        0.2870638673193753,
        0.24851951736491174,
        0.2552763611311093,
        0.30182501405943185,
        0.23189781501423568,
        0.23466089635621756,
        0.25235095573589206,
        0.2658318226458505,
        0.24067189125344157,
        0.19726285594515502,
        0.27139154402539134,
        0.24264398333616555,
        0.2223285953514278,
        0.2508014366030693,
        0.27155080426018685,
        0.2671032107900828,
        0.2608125809347257,
        0.24940161383710802,
        0.2758944222005084,
        0.2458530917065218,
        0.2082646763883531,
        0.23084140464197844,
        0.1855039275251329,
        0.2592771052150056,
        0.25388422317337245,
        0.2315578965935856,
        0.22449559054803103,
        0.22396757663227618,
        0.28526158712338656,
        0.2702488120412454,
        0.2387119228951633
      ],
      "train_rec_loss": [
        0.40030571911484003,
        0.20068207057192922,
        0.18160629412159324,
        0.17318867426365614,
        0.16860390873625875,
        0.16544813616201282,
        0.16259146062657237,
        0.16008594213053584,
        0.15646124351769686,
        0.1667265580035746,
        0.1708180969581008,
        0.1593720461241901,
        0.1560109881684184,
        0.15323436493054032,
        0.15376564068719745,
        0.15833824733272195,
        0.15357631025835872,
        0.1516464981250465,
        0.149103335570544,
        0.1464159651659429,
        0.14298288011923432,
        0.14601380471140146,
        0.13716415269300342,
        0.13131154817529023,
        0.12799830292351544,
        0.1266299239359796,
        0.11985041620209813,
        0.1189720572438091,
        0.11634614993818104,
        0.11110169324092567,
        0.10000653308816254,
        0.09236574987880886,
        0.09514605416916311,
        0.08640496269799769,
        0.08301415224559605,
        0.08194127038586885,
        0.07295230124145746,
        0.07211370184086263,
        0.07231569848954678,
        0.06724894011858851,
        0.06342649844009429,
        0.06438699655700475,
        0.06316123250871897,
        0.06411580624990165,
        0.06273100222460926,
        0.06125506106764078,
        0.05820282734930515,
        0.05593224288895726,
        0.05780160624999553,
        0.055767550715245306,
        0.05420995643362403,
        0.055651741684414446,
        0.054907861980609596,
        0.05159259377978742,
        0.052193645969964564,
        0.05164226342458278,
        0.050039131194353104,
        0.0504620170686394,
        0.04959069634787738,
        0.04839909030124545,
        0.04819370829500258,
        0.047318754834122956,
        0.046497604926116765,
        0.04722982726525515,
        0.047516266466118395,
        0.04721375787630677,
        0.045742307091131806,
        0.04511558695230633,
        0.04619963874574751,
        0.04666072106920183,
        0.04526612162590027,
        0.04491934704128653,
        0.04466407233849168,
        0.04513510467950255,
        0.04463470703922212,
        0.04438070231117308,
        0.04338215955067426,
        0.044060427928343415,
        0.043544193962588906,
        0.043907609418965876,
        0.04397830308880657,
        0.044309286517091095,
        0.04339679144322872,
        0.04315702128224075,
        0.04336094914469868,
        0.04376419342588633,
        0.04297037108335644,
        0.04383307043462992,
        0.04255210352130234,
        0.04292174521833658,
        0.043634721892885864,
        0.04280007118359208,
        0.043126288801431656,
        0.04278200282715261,
        0.043278926983475685,
        0.04312862444203347,
        0.0424850556300953,
        0.04288164561148733,
        0.04268651909660548,
        0.04324505990371108
      ],
      "train_disc_loss": [
        0.10077377123525366,
        0.09064650611253455,
        0.16111664465279318,
        0.24240392388310283,
        0.35585196092142724,
        0.3953732950176345,
        0.4727390389307402,
        0.5719688750541536,
        0.7269775337044848,
        0.6862031783675775,
        0.7800825831654947,
        0.5476730597147252,
        0.5488899592019152,
        0.6049545654677786,
        0.6440951480471995,
        0.6356558375409804,
        0.54221387016878,
        0.6979800360568333,
        0.49109776732802857,
        0.5407034443342127,
        0.6431050868122838,
        0.5976263213669881,
        0.5673233753477689,
        0.4790772969718091,
        0.5825100795482285,
        0.5707945075409953,
        0.6600864838401321,
        0.6190074672631454,
        0.569885206699837,
        0.6028145475429483,
        0.6142123035679106,
        0.6040149733889848,
        0.5524859023280442,
        0.5546065397793427,
        0.6090674116276205,
        0.6815573962812778,
        0.5743384025990963,
        0.598262652871199,
        0.6061822749907151,
        0.42995228769723326,
        0.5985256097628735,
        0.6300247961189598,
        0.6418326760758646,
        0.6693900725804269,
        0.5039910943014547,
        0.527986299188342,
        0.4916410924633965,
        0.5446301093325019,
        0.5226398775703274,
        0.5089933552080765,
        0.4934276784188114,
        0.46133929293137044,
        0.4471951778396033,
        0.42174428194994107,
        0.5145049893762916,
        0.475239829858765,
        0.5659218345535919,
        0.37189528107410297,
        0.4627120459335856,
        0.44491258211201057,
        0.47551441728137434,
        0.5745146269910038,
        0.4094210218754597,
        0.4739124804036692,
        0.39243920508306473,
        0.5047595487558283,
        0.40868710802169517,
        0.4362618381273933,
        0.4685541815706529,
        0.48080628423485905,
        0.4065067881019786,
        0.42071402695728466,
        0.5143218840821646,
        0.37352542398730293,
        0.3800523768295534,
        0.41594051010906696,
        0.4448993277619593,
        0.39322292478755116,
        0.3074373275740072,
        0.45496786915464327,
        0.39733135764254257,
        0.35603861924028024,
        0.41480929037788883,
        0.45678757049608976,
        0.4474845225340687,
        0.4340967769967392,
        0.4128624873701483,
        0.46412269526626915,
        0.4066019718302414,
        0.33068586100125685,
        0.37441336328629404,
        0.2854077150695957,
        0.4323016384150833,
        0.4222044410998933,
        0.37655794114107266,
        0.362733929825481,
        0.3629650465445593,
        0.48475988273276016,
        0.4551245874608867,
        0.39093372656498104
      ],
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100
      ]
    }
  },
  {
    "experiment_name": "Masking_Token",
    "config": {
      "seq_length": 100,
      "num_features": 5,
      "num_train_samples": 1000,
      "num_test_samples": 300,
      "train_anomaly_ratio": 0.05,
      "test_anomaly_ratio": 0.25,
      "d_model": 64,
      "nhead": 4,
      "num_encoder_layers": 3,
      "num_teacher_decoder_layers": 4,
      "num_student_decoder_layers": 1,
      "dim_feedforward": 256,
      "dropout": 0.1,
      "masking_ratio": 0.6,
      "masking_strategy": "token",
      "patch_size": 10,
      "margin": 1.0,
      "lambda_disc": 0.5,
      "batch_size": 32,
      "num_epochs": 100,
      "learning_rate": 0.001,
      "weight_decay": 1e-05,
      "warmup_epochs": 10,
      "mask_last_n": 10,
      "use_discrepancy_loss": true,
      "use_teacher": true,
      "use_student": true,
      "use_masking": true,
      "random_seed": 42,
      "device": "cuda"
    },
    "metrics": {
      "sequence": {
        "roc_auc": 0.8418962962962964,
        "precision": 0.9259259259259259,
        "recall": 0.6666666666666666,
        "f1_score": 0.7751937984496124,
        "optimal_threshold": 0.05447953939437866
      },
      "point": {
        "roc_auc": 0.8012616574875883,
        "precision": 0.2705661557710353,
        "recall": 0.6697638404955478,
        "f1_score": 0.385429430767517,
        "optimal_threshold": 0.011618114076554775
      },
      "combined": {
        "roc_auc": 0.8284020069255346,
        "precision": 0.7082885938443406,
        "recall": 0.6676952019534013,
        "f1_score": 0.6457576002179926,
        "seq_weight": 0.6679116692955567,
        "point_weight": 0.3320883307044433
      }
    },
    "history": {
      "train_loss": [
        0.48590310756117105,
        0.24057823373004794,
        0.2560532111674547,
        0.2967121140100062,
        0.32508656987920403,
        0.35755127016454935,
        0.3808232028968632,
        0.41665232460945845,
        0.4187550125643611,
        0.3516301601193845,
        0.43010436929762363,
        0.2810609380248934,
        0.31544557539746165,
        0.32081954181194305,
        0.3334902562201023,
        0.32071810658089817,
        0.30810083798132837,
        0.29601070436183363,
        0.2837247424758971,
        0.27125752647407353,
        0.2608898663893342,
        0.2539687594398856,
        0.2416159239364788,
        0.25499797496013343,
        0.22430365136824548,
        0.21136863401625305,
        0.2061491176718846,
        0.2516214002389461,
        0.23257957969326526,
        0.19657480507157743,
        0.2342311767861247,
        0.21007718320470303,
        0.21480654762126505,
        0.192935973405838,
        0.2006694609299302,
        0.16622633999213576,
        0.26907134673092514,
        0.1931121137458831,
        0.19538991467561573,
        0.17098241369239986,
        0.2168231294490397,
        0.1804373583290726,
        0.15415198192931712,
        0.1863831013906747,
        0.1499153677141294,
        0.18614977155812085,
        0.14733473886735737,
        0.1552788648987189,
        0.18422484886832535,
        0.15021319687366486,
        0.18184971739538014,
        0.1764533445239067,
        0.1578777754912153,
        0.2144420564873144,
        0.16071738163009286,
        0.11905717861372977,
        0.15623633447103202,
        0.14924026746302843,
        0.1341915710363537,
        0.13670757529325783,
        0.14395625423640013,
        0.1305210969876498,
        0.16753995313774794,
        0.16350126266479492,
        0.16407456889282912,
        0.13775617023929954,
        0.1319407196715474,
        0.19574591156560928,
        0.18111455324105918,
        0.14224032335914671,
        0.13161945180036128,
        0.14196868357248604,
        0.1354628287954256,
        0.13087276415899396,
        0.13241871574427933,
        0.11449591035488993,
        0.1279031188460067,
        0.10281149530783296,
        0.13247685611713678,
        0.10536308283917606,
        0.10557473916560411,
        0.14707181381527334,
        0.11750804237090051,
        0.08295945840654895,
        0.09961088350974023,
        0.09998198878020048,
        0.11465316906105727,
        0.09063440153840929,
        0.11420261213788763,
        0.11146707856096327,
        0.11156538012437522,
        0.08365060586947948,
        0.10396609106101096,
        0.13273050088901073,
        0.1458999802125618,
        0.11062428937293589,
        0.0900722504593432,
        0.1100460261804983,
        0.11151258181780577,
        0.09990850230678916
      ],
      "train_rec_loss": [
        0.41331863636150956,
        0.19388014264404774,
        0.1675125891342759,
        0.16294308099895716,
        0.16057254653424025,
        0.1530348234809935,
        0.15542100509628654,
        0.1516519500873983,
        0.13241930538788438,
        0.11034584557637572,
        0.08048063074238598,
        0.06256202084477991,
        0.06912084599025548,
        0.0693760538706556,
        0.05789072881452739,
        0.06709347735159099,
        0.058562348945997655,
        0.06326597335282713,
        0.055268989061005414,
        0.05622164311353117,
        0.04546976834535599,
        0.05965449474751949,
        0.0468129285145551,
        0.047996669774875045,
        0.04531384853180498,
        0.04258891148492694,
        0.04428675305098295,
        0.05413220904301852,
        0.04618403874337673,
        0.040293198195286095,
        0.039735153783112764,
        0.040340565028600395,
        0.040354239172302186,
        0.03960888797882944,
        0.04011477599851787,
        0.03960097336675972,
        0.03800805390346795,
        0.04009773244615644,
        0.0371259031817317,
        0.03712490142788738,
        0.03971280972473323,
        0.03690410032868385,
        0.036495642038062215,
        0.03658187948167324,
        0.035410571144893765,
        0.036311155068688095,
        0.03635452629532665,
        0.03474206355167553,
        0.03463363053742796,
        0.03474570991238579,
        0.036239022738300264,
        0.03383477189345285,
        0.03467879048548639,
        0.03550820704549551,
        0.034628002147655934,
        0.03369900118559599,
        0.03292714658891782,
        0.03366913378704339,
        0.03315170470159501,
        0.03311868180753663,
        0.032986481790430844,
        0.03286362602375448,
        0.03294110100250691,
        0.03353770560352132,
        0.03416101139737293,
        0.03410372254438698,
        0.03289704903727397,
        0.03266275639180094,
        0.03268481162376702,
        0.03242083732038736,
        0.03265748702688143,
        0.03261850739363581,
        0.03232252469751984,
        0.03197781182825565,
        0.032246751070488244,
        0.03250771504826844,
        0.032196109532378614,
        0.03232519130688161,
        0.03203393827425316,
        0.0320590830524452,
        0.03214571566786617,
        0.03227731952210888,
        0.032264680485241115,
        0.031738744815811515,
        0.03180449764477089,
        0.0319430215167813,
        0.03191337443422526,
        0.03185090306214988,
        0.03181841399054974,
        0.03161679126787931,
        0.03184779913863167,
        0.031461380305700004,
        0.031577824731357396,
        0.03160487022250891,
        0.03151838079793379,
        0.03178795403800905,
        0.03162592853186652,
        0.03176821593660861,
        0.03162986761890352,
        0.03137789212632924
      ],
      "train_disc_loss": [
        0.1451689486275427,
        0.09339618516969495,
        0.17708124336786568,
        0.26753806497436017,
        0.3290280429646373,
        0.40903288693516515,
        0.4508043924724916,
        0.5300007491314318,
        0.5726714123447891,
        0.48256862768903375,
        0.6992474722210318,
        0.4369978358154185,
        0.49264945928007364,
        0.5028869758825749,
        0.5511990475351922,
        0.5072492610197514,
        0.4990769831347279,
        0.46548945939866826,
        0.4569115054910071,
        0.4300717619480565,
        0.43084019131492823,
        0.38862852804595605,
        0.3896059896214865,
        0.41400261386297643,
        0.357979609281756,
        0.3375594394747168,
        0.3237247306969948,
        0.39497838250827044,
        0.37279107654467225,
        0.31256321375258267,
        0.38899204577319324,
        0.3394732355955057,
        0.34890461358008906,
        0.30665416532428935,
        0.32110937242396176,
        0.2532507333671674,
        0.46212658466538414,
        0.30602876225020736,
        0.31652802182361484,
        0.2677150249364786,
        0.3542206408455968,
        0.2870665122172795,
        0.23531268502119929,
        0.29960244393441826,
        0.22900959273101762,
        0.2996772253245581,
        0.2219604238634929,
        0.2410735973098781,
        0.2991824381169863,
        0.2309349732240662,
        0.2912213887902908,
        0.2852371486951597,
        0.24639797244162764,
        0.3578677022596821,
        0.25217875809175894,
        0.1707163544924697,
        0.24661837343592197,
        0.23114226692996453,
        0.20207973082142416,
        0.2071777861128794,
        0.22193954580870923,
        0.1953149447654141,
        0.2691977042122744,
        0.25992711511207744,
        0.2598271138704149,
        0.2073048928868957,
        0.19808734446996823,
        0.32616631129349116,
        0.2968594870180823,
        0.2196389743767213,
        0.1979239275387954,
        0.2187003574654227,
        0.20628060653689317,
        0.19778990709164646,
        0.20034392550587654,
        0.16397639106435236,
        0.19141401567321736,
        0.14097260536800604,
        0.20088583487085998,
        0.1466079997480847,
        0.14685805003682617,
        0.2295889862580225,
        0.17048672660894226,
        0.10244142627925612,
        0.13561277161352336,
        0.13607793855771888,
        0.1654795895301504,
        0.11756699667603243,
        0.16476839869574178,
        0.15970057387312409,
        0.15943516371771693,
        0.10437844965781551,
        0.14477653297944926,
        0.20225126316654496,
        0.2287632001680322,
        0.157672670786269,
        0.11689264446613379,
        0.15655562236497644,
        0.15976542909629643,
        0.1370612209138926
      ],
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100
      ]
    }
  },
  {
    "experiment_name": "Masking_Temporal",
    "config": {
      "seq_length": 100,
      "num_features": 5,
      "num_train_samples": 1000,
      "num_test_samples": 300,
      "train_anomaly_ratio": 0.05,
      "test_anomaly_ratio": 0.25,
      "d_model": 64,
      "nhead": 4,
      "num_encoder_layers": 3,
      "num_teacher_decoder_layers": 4,
      "num_student_decoder_layers": 1,
      "dim_feedforward": 256,
      "dropout": 0.1,
      "masking_ratio": 0.6,
      "masking_strategy": "temporal",
      "patch_size": 10,
      "margin": 1.0,
      "lambda_disc": 0.5,
      "batch_size": 32,
      "num_epochs": 100,
      "learning_rate": 0.001,
      "weight_decay": 1e-05,
      "warmup_epochs": 10,
      "mask_last_n": 10,
      "use_discrepancy_loss": true,
      "use_teacher": true,
      "use_student": true,
      "use_masking": true,
      "random_seed": 42,
      "device": "cuda"
    },
    "metrics": {
      "sequence": {
        "roc_auc": 0.8585481481481482,
        "precision": 0.9818181818181818,
        "recall": 0.72,
        "f1_score": 0.8307692307692308,
        "optimal_threshold": 0.05936954542994499
      },
      "point": {
        "roc_auc": 0.8093138138067534,
        "precision": 0.28149158708503863,
        "recall": 0.718931475029036,
        "f1_score": 0.4045751633986928,
        "optimal_threshold": 0.030859991908073425
      },
      "combined": {
        "roc_auc": 0.842423908660736,
        "precision": 0.7524612932984795,
        "recall": 0.7196500581807272,
        "f1_score": 0.6911907170689044,
        "seq_weight": 0.6725001017459606,
        "point_weight": 0.3274998982540393
      }
    },
    "history": {
      "train_loss": [
        0.4846909111365676,
        0.24226423585787416,
        0.25629379879683256,
        0.2982571395114064,
        0.3226061761379242,
        0.3571224524639547,
        0.3713900023140013,
        0.3986714230850339,
        0.36828292324207723,
        0.3522040448151529,
        0.3908043841365725,
        0.2791209666756913,
        0.2994091836735606,
        0.3056479870574549,
        0.3006684195715934,
        0.2800005516037345,
        0.31431145628448576,
        0.27462217619176954,
        0.3130305069498718,
        0.27568384900223464,
        0.28749592311214656,
        0.3487133536254987,
        0.24929470126517117,
        0.28858551545999944,
        0.22608469845727086,
        0.2083654401358217,
        0.22988659550901502,
        0.24730624991934747,
        0.2266562518198043,
        0.2288652218412608,
        0.24786668876186013,
        0.19474060426000506,
        0.23997975199017674,
        0.20211256004404277,
        0.24294382624793798,
        0.15930213348474354,
        0.2841057135956362,
        0.18997980281710625,
        0.22913299361243844,
        0.15719132032245398,
        0.1855129118775949,
        0.19637549528852105,
        0.15824192261788994,
        0.16211518947966397,
        0.150939712068066,
        0.1529927214141935,
        0.14903066703118384,
        0.14501645253039896,
        0.1815728604560718,
        0.14364209247287363,
        0.17384948453400284,
        0.18395954358857125,
        0.18571780831553042,
        0.18091696477495134,
        0.14584108022972941,
        0.11823363194707781,
        0.14326410077046603,
        0.15997845388483256,
        0.12454749341122806,
        0.12067532516084611,
        0.12542412511538714,
        0.10913812799844891,
        0.12408079917076975,
        0.1377289118245244,
        0.11181300214957446,
        0.13933336699847132,
        0.10018012719228864,
        0.14897657476831228,
        0.11362951202318072,
        0.09900935646146536,
        0.09864255564752966,
        0.10332874662708491,
        0.08203122450504452,
        0.09416792553383857,
        0.09745287767145783,
        0.07816012424882501,
        0.09303594008088112,
        0.08679580397438258,
        0.09349786071106791,
        0.08508554333820939,
        0.08055641839746386,
        0.09562778857070953,
        0.10365361091680825,
        0.07237899291794747,
        0.08084244641941041,
        0.09250663220882416,
        0.09991173818707466,
        0.07983184116892517,
        0.07957828952930868,
        0.10760234156623483,
        0.08367198251653463,
        0.0655855227378197,
        0.09772189240902662,
        0.08816642803139985,
        0.0908266621408984,
        0.08891399763524532,
        0.06524830684065819,
        0.07894433161709458,
        0.07957909698598087,
        0.08426358050201088
      ],
      "train_rec_loss": [
        0.41224143002182245,
        0.19531453121453524,
        0.16771761793643236,
        0.16425705840811133,
        0.15823926497250795,
        0.15304078627377748,
        0.15812339866533875,
        0.14287995360791683,
        0.1341588399372995,
        0.09757419466041028,
        0.07111982954666018,
        0.05839813605416566,
        0.05200627644080669,
        0.04779667349066585,
        0.0491527538979426,
        0.04838190309237689,
        0.046966279740445316,
        0.04933586705010384,
        0.04474011203274131,
        0.05364889930933714,
        0.050872880150564015,
        0.05873523710761219,
        0.04877185367513448,
        0.04242142359726131,
        0.04199635982513428,
        0.041563318809494376,
        0.04045515297912061,
        0.042946320376358926,
        0.045056650997139513,
        0.042137564974837005,
        0.039218579535372555,
        0.04137547453865409,
        0.0410906319739297,
        0.03960004332475364,
        0.03937490005046129,
        0.03835458972025663,
        0.03717635362409055,
        0.03779820573981851,
        0.03824113460723311,
        0.03648557065753266,
        0.03631319082342088,
        0.036668505519628525,
        0.03872485214378685,
        0.039600893622264266,
        0.03638164000585675,
        0.03544660995248705,
        0.03513284417567775,
        0.036214305204339325,
        0.03533588256686926,
        0.03502303431741893,
        0.03483453416265547,
        0.034438842558301985,
        0.03522140614222735,
        0.03529388236347586,
        0.03549436794128269,
        0.034318688965868205,
        0.034218031039927155,
        0.03517102636396885,
        0.0345909470343031,
        0.03387697460129857,
        0.03333664097590372,
        0.033310035592876375,
        0.03367237385828048,
        0.032894059317186475,
        0.032671771477907896,
        0.032408119179308414,
        0.032613348856102675,
        0.03254622837994248,
        0.03267658199183643,
        0.03233877045568079,
        0.0323798677418381,
        0.03235207166289911,
        0.03218883491354063,
        0.03178175468929112,
        0.03204065148020163,
        0.03198376978980377,
        0.03163430804852396,
        0.031479187426157296,
        0.0314409828861244,
        0.03135073749581352,
        0.03156271210173145,
        0.031239809119142592,
        0.03154179314151406,
        0.03101148543646559,
        0.031196872296277434,
        0.03127331467112526,
        0.03116294671781361,
        0.03108603076543659,
        0.031062986934557557,
        0.030971899221185595,
        0.031012467166874558,
        0.030731176084373146,
        0.030792589765042067,
        0.030803093512076885,
        0.030761663161683828,
        0.031124537985306233,
        0.030879506608471274,
        0.03082805481972173,
        0.03083680843701586,
        0.030684247089084238
      ],
      "train_disc_loss": [
        0.1448989626369439,
        0.09389941094559617,
        0.17715236436924897,
        0.26800015998014715,
        0.32873382487741765,
        0.4081633325695293,
        0.4265332038048655,
        0.5115829507121816,
        0.4682481665513478,
        0.5092597031907644,
        0.6393691095872782,
        0.44144566246541217,
        0.49480581894749776,
        0.5157026335946284,
        0.503031330415979,
        0.46323729312280193,
        0.5346903565805405,
        0.4505726177012548,
        0.5365807882044464,
        0.4440698980470188,
        0.4732460790546611,
        0.5799562333268113,
        0.40104569180402905,
        0.49232818523887545,
        0.36817667935974896,
        0.3336042453884147,
        0.3788628830225207,
        0.4087198593770154,
        0.3631992007722147,
        0.37345531495520845,
        0.41729621740523726,
        0.3067302642739378,
        0.3977782447473146,
        0.3250250287819654,
        0.40713784511899576,
        0.24189508793642744,
        0.4938587252981961,
        0.30436319182626903,
        0.38178371835965663,
        0.2414114993880503,
        0.2983994454261847,
        0.31941397866467014,
        0.2390341447899118,
        0.24502859020140022,
        0.22911614266922697,
        0.23509222554275766,
        0.227795644197613,
        0.2176042950595729,
        0.2924739560112357,
        0.2172381164273247,
        0.2780299012665637,
        0.2990414006926585,
        0.3009928039100487,
        0.29124616298940964,
        0.2206934261485003,
        0.1678298870101571,
        0.21809213975211605,
        0.24961485847597942,
        0.17991309211356565,
        0.1735967024578713,
        0.18417496638721786,
        0.15165618539322168,
        0.18081685370998457,
        0.2096697098459117,
        0.15828245747252367,
        0.21385049287346192,
        0.13513355562463403,
        0.2328606923983898,
        0.16190585980075411,
        0.1333411730302032,
        0.13252537490916438,
        0.1419533500156831,
        0.09968478078371845,
        0.12477234250400215,
        0.13082445177133195,
        0.09235270910721738,
        0.1228032656799769,
        0.11063323399866931,
        0.12411375650845002,
        0.10746961191762239,
        0.09798741081613116,
        0.12877595945610665,
        0.14422363514313474,
        0.08273501176154241,
        0.09929114702390507,
        0.12246663453697693,
        0.13749758497579023,
        0.09749162038497161,
        0.09703060521860607,
        0.153260883394978,
        0.10531903299852274,
        0.06970869416545611,
        0.13385860653943382,
        0.11472666698682588,
        0.12012999989383388,
        0.11557892047858331,
        0.068737601293833,
        0.09623255323094781,
        0.09748457619571127,
        0.10715866486134473
      ],
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100
      ]
    }
  },
  {
    "experiment_name": "Masking_FeatureWise",
    "config": {
      "seq_length": 100,
      "num_features": 5,
      "num_train_samples": 1000,
      "num_test_samples": 300,
      "train_anomaly_ratio": 0.05,
      "test_anomaly_ratio": 0.25,
      "d_model": 64,
      "nhead": 4,
      "num_encoder_layers": 3,
      "num_teacher_decoder_layers": 4,
      "num_student_decoder_layers": 1,
      "dim_feedforward": 256,
      "dropout": 0.1,
      "masking_ratio": 0.6,
      "masking_strategy": "feature_wise",
      "patch_size": 10,
      "margin": 1.0,
      "lambda_disc": 0.5,
      "batch_size": 32,
      "num_epochs": 100,
      "learning_rate": 0.001,
      "weight_decay": 1e-05,
      "warmup_epochs": 10,
      "mask_last_n": 10,
      "use_discrepancy_loss": true,
      "use_teacher": true,
      "use_student": true,
      "use_masking": true,
      "random_seed": 42,
      "device": "cuda"
    },
    "metrics": {
      "sequence": {
        "roc_auc": 0.8282666666666667,
        "precision": 0.9056603773584906,
        "recall": 0.64,
        "f1_score": 0.75,
        "optimal_threshold": 0.09063901007175446
      },
      "point": {
        "roc_auc": 0.728962616639125,
        "precision": 0.26716206652512386,
        "recall": 0.5845915602013163,
        "f1_score": 0.36672738312082576,
        "optimal_threshold": 0.11455608904361725
      },
      "combined": {
        "roc_auc": 0.7956557403561406,
        "precision": 0.6959808994499118,
        "recall": 0.6218041605880631,
        "f1_score": 0.6241352939540459,
        "seq_weight": 0.6716052738888134,
        "point_weight": 0.32839472611118664
      }
    },
    "history": {
      "train_loss": [
        0.3428059397265315,
        0.1780314133502543,
        0.20403099479153752,
        0.24496410437859595,
        0.2752023763023317,
        0.3125409681815654,
        0.33247714559547603,
        0.4024185389280319,
        0.43135915813036263,
        0.44096382590942085,
        0.5379132193047553,
        0.4569779457524419,
        0.48359048017300665,
        0.5440426727291197,
        0.4975610498804599,
        0.48126975959166884,
        0.5440003972034901,
        0.5132719206158072,
        0.5274541445542127,
        0.4872595309279859,
        0.46534796082414687,
        0.5443197679705918,
        0.5127480300143361,
        0.512375723104924,
        0.48132623406127095,
        0.48022983712144196,
        0.4960157535970211,
        0.5025956591125578,
        0.4474449553526938,
        0.5130129472818226,
        0.5114532120060176,
        0.474962659412995,
        0.48013486014679074,
        0.4016623576171696,
        0.41361853177659214,
        0.3918594801798463,
        0.44585646758787334,
        0.44536270457319915,
        0.399080547504127,
        0.35126127069815993,
        0.3369947699829936,
        0.3141948850825429,
        0.29765827173832804,
        0.24809408863075078,
        0.27712377661373466,
        0.251600174815394,
        0.2593306606868282,
        0.24116209731437266,
        0.27323650650214404,
        0.24739816668443382,
        0.25239596981555223,
        0.27966133097652346,
        0.24932449555490166,
        0.2809551889076829,
        0.23824308160692453,
        0.23627148405648768,
        0.22798360174056143,
        0.2255312786437571,
        0.2617848855443299,
        0.20121860259678215,
        0.23490200249943882,
        0.27944203303195536,
        0.22432851023040712,
        0.24541548313573003,
        0.212650001863949,
        0.2524915545945987,
        0.1834130259230733,
        0.24478012474719435,
        0.22308399353642017,
        0.24326556455343962,
        0.2331808782182634,
        0.22358710248954594,
        0.2513350505614653,
        0.20385380333755165,
        0.2031812514178455,
        0.1865062190918252,
        0.19999570352956653,
        0.1906567447585985,
        0.1698266692692414,
        0.17853286839090288,
        0.2530296198092401,
        0.21475656691472977,
        0.17563872213941067,
        0.1818938134238124,
        0.22151698358356953,
        0.22814597561955452,
        0.17888667155057192,
        0.1966319753555581,
        0.22198169433977455,
        0.20459387509617954,
        0.1777178451884538,
        0.21126159757841378,
        0.1855451539158821,
        0.1814218576764688,
        0.21027978335041553,
        0.2023683573352173,
        0.22581426496617496,
        0.24450881697703153,
        0.1750880954787135,
        0.21122916031163186
      ],
      "train_rec_loss": [
        0.2741190935485065,
        0.13169023534283042,
        0.11533191497437656,
        0.11116365483030677,
        0.11057170247659087,
        0.10802092566154897,
        0.10634843329899013,
        0.10571390413679183,
        0.1306977013591677,
        0.1108114558737725,
        0.12193312076851726,
        0.1142854958306998,
        0.11110695358365774,
        0.10615280154161155,
        0.10645868722349405,
        0.10568609065376222,
        0.1060684178955853,
        0.10560422949492931,
        0.10540061048232019,
        0.10835833963938057,
        0.11262528784573078,
        0.10639966907911003,
        0.1060063554905355,
        0.10579132311977446,
        0.10590820340439677,
        0.10490667191334069,
        0.1051206320989877,
        0.10697119659744203,
        0.11154746217653155,
        0.10592680680565536,
        0.10482119675725698,
        0.10480893845669925,
        0.10452627344056964,
        0.10424963803961873,
        0.10329435905441642,
        0.10212835646234453,
        0.10147602413780987,
        0.1037480952218175,
        0.0996293902862817,
        0.09261067700572312,
        0.08002252574078739,
        0.05951168725732714,
        0.05252866121008992,
        0.04435782693326473,
        0.04269026510883123,
        0.03969972871709615,
        0.03656585165299475,
        0.03486016782699153,
        0.03338216373231262,
        0.03174017777200788,
        0.0319274696521461,
        0.03202805173350498,
        0.032737326342612505,
        0.033372290374245495,
        0.03241704130778089,
        0.03020750597352162,
        0.03161891730269417,
        0.03213338815839961,
        0.02992786408867687,
        0.030589573900215328,
        0.029359855165239424,
        0.029086446680594236,
        0.03023941395804286,
        0.029563779768068343,
        0.028356805443763733,
        0.028439058805815876,
        0.028485419636126608,
        0.02793981443392113,
        0.03115824528504163,
        0.028251197712961584,
        0.030498150503262877,
        0.029106441244948655,
        0.027582316659390926,
        0.027866663702297956,
        0.027445056941360235,
        0.027742152626160532,
        0.027586823503952473,
        0.027419638470746577,
        0.027472129790112376,
        0.02817488182336092,
        0.02654074993915856,
        0.027250380371697247,
        0.02756847650744021,
        0.026607050676830113,
        0.027047895127907395,
        0.02766474086092785,
        0.027011289726942778,
        0.02693014807300642,
        0.02604071475798264,
        0.026507953880354762,
        0.026435031497385353,
        0.02641551662236452,
        0.026061557175125927,
        0.026178893924225122,
        0.02627071045571938,
        0.026100601942744106,
        0.026185622322373092,
        0.02626658562803641,
        0.02604759018868208,
        0.02603792300214991
      ],
      "train_disc_loss": [
        0.1373736932873726,
        0.09268235522904433,
        0.17739816044922918,
        0.2676008976995945,
        0.3292613513767719,
        0.409040085185552,
        0.4522574236179935,
        0.5934092683964991,
        0.6013229179952759,
        0.660304738979903,
        0.8319601977709681,
        0.6853849071485456,
        0.7449670512287412,
        0.8757797443977324,
        0.7822047229856253,
        0.7511673430853989,
        0.87586396370898,
        0.8153353824891383,
        0.8441070631088223,
        0.7578023897949606,
        0.7054453484888654,
        0.8758401835802943,
        0.8134833564545261,
        0.8131687928325846,
        0.7508360618667211,
        0.7506463280806202,
        0.7817902341557783,
        0.7912489314112463,
        0.6717949814046733,
        0.8141722861037124,
        0.8132640185503988,
        0.7403074379399186,
        0.7512171652488178,
        0.5948254438844742,
        0.6206483360583661,
        0.5794622452231124,
        0.6887608819815796,
        0.6832292164326645,
        0.5989023186120903,
        0.5173011777515057,
        0.5139444930828176,
        0.5093663979496341,
        0.4902592196012847,
        0.40747252700384706,
        0.4688670231262222,
        0.4238008903339505,
        0.44552961154840887,
        0.4126038629328832,
        0.4797086876933463,
        0.43131597753381357,
        0.44093700632220134,
        0.4952665552846156,
        0.433174337958917,
        0.4951657936326228,
        0.4116520794632379,
        0.41212795954197645,
        0.39272936835186556,
        0.3867957772454247,
        0.46371404523961246,
        0.34125806426163763,
        0.4110842976369895,
        0.5007111709564924,
        0.3881781962700188,
        0.43170341063523665,
        0.3685863906284794,
        0.44810499832965434,
        0.3098552123410627,
        0.43368062033550814,
        0.3838514963281341,
        0.430028734554071,
        0.40536545537179336,
        0.3889613188803196,
        0.4475054678041488,
        0.3519742750795558,
        0.35147238470381126,
        0.3175281332223676,
        0.344817757839337,
        0.32647420943249017,
        0.28470908204326406,
        0.300715975696221,
        0.45297773636411875,
        0.37501237023388967,
        0.29614048870280385,
        0.31057352537754923,
        0.3889381801709533,
        0.40096246905159205,
        0.30375076160999015,
        0.3394036545068957,
        0.3918819609680213,
        0.3561718450509943,
        0.3025656279642135,
        0.3696921613300219,
        0.31896719470387325,
        0.3104859263403341,
        0.36801814642967656,
        0.3525355131714605,
        0.3992572889546864,
        0.4364844576921314,
        0.29808101133676246,
        0.37038247630698606
      ],
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100
      ]
    }
  },
  {
    "experiment_name": "Ablation_NoDiscrepancy",
    "config": {
      "seq_length": 100,
      "num_features": 5,
      "num_train_samples": 1000,
      "num_test_samples": 300,
      "train_anomaly_ratio": 0.05,
      "test_anomaly_ratio": 0.25,
      "d_model": 64,
      "nhead": 4,
      "num_encoder_layers": 3,
      "num_teacher_decoder_layers": 4,
      "num_student_decoder_layers": 1,
      "dim_feedforward": 256,
      "dropout": 0.1,
      "masking_ratio": 0.6,
      "masking_strategy": "patch",
      "patch_size": 10,
      "margin": 1.0,
      "lambda_disc": 0.5,
      "batch_size": 32,
      "num_epochs": 100,
      "learning_rate": 0.001,
      "weight_decay": 1e-05,
      "warmup_epochs": 10,
      "mask_last_n": 10,
      "use_discrepancy_loss": false,
      "use_teacher": true,
      "use_student": true,
      "use_masking": true,
      "random_seed": 42,
      "device": "cuda"
    },
    "metrics": {
      "sequence": {
        "roc_auc": 0.4809481481481482,
        "precision": 0.2676056338028169,
        "recall": 0.76,
        "f1_score": 0.3958333333333333,
        "optimal_threshold": 0.36437198519706726
      },
      "point": {
        "roc_auc": 0.5151365517219176,
        "precision": 0.09153576675330546,
        "recall": 0.627177700348432,
        "f1_score": 0.15975543612247917,
        "optimal_threshold": 0.3172599971294403
      },
      "combined": {
        "roc_auc": 0.4907787704060613,
        "precision": 0.21697804745676363,
        "recall": 0.7218079313798756,
        "f1_score": 0.3279508823170203,
        "seq_weight": 0.7124574057194204,
        "point_weight": 0.2875425942805796
      }
    },
    "history": {
      "train_loss": [
        0.3998747328296304,
        0.20343323331326246,
        0.1835830882191658,
        0.17464664159342647,
        0.16917687561362982,
        0.1659717569127679,
        0.1628908710554242,
        0.16096149431541562,
        0.15656241495162249,
        0.15394869912415743,
        0.1501795663498342,
        0.14430838194675744,
        0.13923103781417012,
        0.12981215841136873,
        0.12200363026931882,
        0.11430649808607996,
        0.10684034810401499,
        0.09898164309561253,
        0.0885023339651525,
        0.07980593666434288,
        0.07527415337972343,
        0.06831755547318608,
        0.06276729935780168,
        0.06266948254778981,
        0.06051127007231116,
        0.057998152798973024,
        0.05602402472868562,
        0.05351659026928246,
        0.05162942036986351,
        0.052498122211545706,
        0.050557255861349404,
        0.04903752531390637,
        0.047263267217203975,
        0.0486447224393487,
        0.04799476801417768,
        0.04754856741055846,
        0.045422976720146835,
        0.045534520875662565,
        0.04488968965597451,
        0.0436443475773558,
        0.04359728330746293,
        0.04382313811220229,
        0.04300094034988433,
        0.04273823683615774,
        0.04177661577705294,
        0.04172722704242915,
        0.04103091801516712,
        0.04167715006042272,
        0.04134689783677459,
        0.04088230093475431,
        0.041148393182083964,
        0.04111480538267642,
        0.04047046764753759,
        0.04053442436270416,
        0.03983467351645231,
        0.03974815609399229,
        0.03969035530462861,
        0.04037422768305987,
        0.03976400045212358,
        0.03910370112862438,
        0.03892176621593535,
        0.038969164015725255,
        0.03807008021976799,
        0.039320917800068855,
        0.03861018980387598,
        0.03851162100909278,
        0.0380408480996266,
        0.03768553724512458,
        0.038719424162991345,
        0.038041180348955095,
        0.038360362756066024,
        0.03768317878711969,
        0.03782669035717845,
        0.03803320217411965,
        0.03745165129657835,
        0.03734424663707614,
        0.037688658805564046,
        0.037628487101756036,
        0.03701192996231839,
        0.03697082388680428,
        0.037193419644609094,
        0.03706266428343952,
        0.037121459492482245,
        0.03695668699219823,
        0.03699219005648047,
        0.036811397527344525,
        0.03679612942505628,
        0.03691794036421925,
        0.036921596503816545,
        0.03673557995352894,
        0.036895113182254136,
        0.03642204456264153,
        0.03692995570600033,
        0.03676202776841819,
        0.036975794355385005,
        0.0367759132059291,
        0.036661872756667435,
        0.03652408090420067,
        0.03634632041212171,
        0.03674726514145732
      ],
      "train_rec_loss": [
        0.3998747328296304,
        0.20343323331326246,
        0.1835830882191658,
        0.17464664159342647,
        0.16917687561362982,
        0.1659717569127679,
        0.1628908710554242,
        0.16096149431541562,
        0.15656241495162249,
        0.15394869912415743,
        0.1501795663498342,
        0.14430838194675744,
        0.13923103781417012,
        0.12981215841136873,
        0.12200363026931882,
        0.11430649808607996,
        0.10684034810401499,
        0.09898164309561253,
        0.0885023339651525,
        0.07980593666434288,
        0.07527415337972343,
        0.06831755547318608,
        0.06276729935780168,
        0.06266948254778981,
        0.06051127007231116,
        0.057998152798973024,
        0.05602402472868562,
        0.05351659026928246,
        0.05162942036986351,
        0.052498122211545706,
        0.050557255861349404,
        0.04903752531390637,
        0.047263267217203975,
        0.0486447224393487,
        0.04799476801417768,
        0.04754856741055846,
        0.045422976720146835,
        0.045534520875662565,
        0.04488968965597451,
        0.0436443475773558,
        0.04359728330746293,
        0.04382313811220229,
        0.04300094034988433,
        0.04273823683615774,
        0.04177661577705294,
        0.04172722704242915,
        0.04103091801516712,
        0.04167715006042272,
        0.04134689783677459,
        0.04088230093475431,
        0.041148393182083964,
        0.04111480538267642,
        0.04047046764753759,
        0.04053442436270416,
        0.03983467351645231,
        0.03974815609399229,
        0.03969035530462861,
        0.04037422768305987,
        0.03976400045212358,
        0.03910370112862438,
        0.03892176621593535,
        0.038969164015725255,
        0.03807008021976799,
        0.039320917800068855,
        0.03861018980387598,
        0.03851162100909278,
        0.0380408480996266,
        0.03768553724512458,
        0.038719424162991345,
        0.038041180348955095,
        0.038360362756066024,
        0.03768317878711969,
        0.03782669035717845,
        0.03803320217411965,
        0.03745165129657835,
        0.03734424663707614,
        0.037688658805564046,
        0.037628487101756036,
        0.03701192996231839,
        0.03697082388680428,
        0.037193419644609094,
        0.03706266428343952,
        0.037121459492482245,
        0.03695668699219823,
        0.03699219005648047,
        0.036811397527344525,
        0.03679612942505628,
        0.03691794036421925,
        0.036921596503816545,
        0.03673557995352894,
        0.036895113182254136,
        0.03642204456264153,
        0.03692995570600033,
        0.03676202776841819,
        0.036975794355385005,
        0.0367759132059291,
        0.036661872756667435,
        0.03652408090420067,
        0.03634632041212171,
        0.03674726514145732
      ],
      "train_disc_loss": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100
      ]
    }
  },
  {
    "experiment_name": "Ablation_TeacherOnly",
    "config": {
      "seq_length": 100,
      "num_features": 5,
      "num_train_samples": 1000,
      "num_test_samples": 300,
      "train_anomaly_ratio": 0.05,
      "test_anomaly_ratio": 0.25,
      "d_model": 64,
      "nhead": 4,
      "num_encoder_layers": 3,
      "num_teacher_decoder_layers": 4,
      "num_student_decoder_layers": 1,
      "dim_feedforward": 256,
      "dropout": 0.1,
      "masking_ratio": 0.6,
      "masking_strategy": "patch",
      "patch_size": 10,
      "margin": 1.0,
      "lambda_disc": 0.5,
      "batch_size": 32,
      "num_epochs": 100,
      "learning_rate": 0.001,
      "weight_decay": 1e-05,
      "warmup_epochs": 10,
      "mask_last_n": 10,
      "use_discrepancy_loss": false,
      "use_teacher": true,
      "use_student": false,
      "use_masking": true,
      "random_seed": 42,
      "device": "cuda"
    },
    "metrics": {
      "sequence": {
        "roc_auc": 0.7179851851851851,
        "precision": 0.4336283185840708,
        "recall": 0.6533333333333333,
        "f1_score": 0.5212765957446809,
        "optimal_threshold": 0.007993093691766262
      },
      "point": {
        "roc_auc": 0.7405826455890642,
        "precision": 0.19862122788761707,
        "recall": 0.5911730545876888,
        "f1_score": 0.297342030960958,
        "optimal_threshold": 0.010360591113567352
      },
      "combined": {
        "roc_auc": 0.7261931278728431,
        "precision": 0.3482680746825643,
        "recall": 0.6307552207368613,
        "f1_score": 0.439938160332933,
        "seq_weight": 0.636775879193527,
        "point_weight": 0.363224120806473
      }
    },
    "history": {
      "train_loss": [
        0.3943795822560787,
        0.2045424710959196,
        0.18443073192611337,
        0.17570023937150836,
        0.17048219591379166,
        0.16629208298400044,
        0.1615586094558239,
        0.15910393092781305,
        0.15315458457916975,
        0.1457584290765226,
        0.13800786016508937,
        0.12929745041765273,
        0.12440425250679255,
        0.11497116298414767,
        0.10619156085886061,
        0.09373338497243822,
        0.08881734753958881,
        0.07613842864520848,
        0.07144977059215307,
        0.06847484945319593,
        0.06270273332484066,
        0.05864044767804444,
        0.05767787399236113,
        0.05620420223567635,
        0.054322551703080535,
        0.052799774217419326,
        0.05093509634025395,
        0.05015012284275144,
        0.04944017750676721,
        0.050873333238996565,
        0.0500002121552825,
        0.04926569841336459,
        0.04661209334153682,
        0.046349435462616384,
        0.045635541435331106,
        0.044639263418503106,
        0.04547391680534929,
        0.04593824013136327,
        0.04463441018015146,
        0.043851940892636776,
        0.0431492745410651,
        0.04235448129475117,
        0.04279364307876676,
        0.043963787029497325,
        0.04192765580955893,
        0.04120460315607488,
        0.041360886418260634,
        0.04128967737779021,
        0.041058548144064844,
        0.040393217583186924,
        0.041169354459270835,
        0.040578093263320625,
        0.03990712354425341,
        0.039422713802196085,
        0.03954122506547719,
        0.03979158482979983,
        0.03979587915819138,
        0.039704321417957544,
        0.03892582328990102,
        0.03907457331661135,
        0.03870791872031987,
        0.039361068746075034,
        0.03846495458856225,
        0.03856241225730628,
        0.03857726766727865,
        0.0381682887673378,
        0.03808304853737354,
        0.03783863713033497,
        0.03804289049003273,
        0.03794315014965832,
        0.03748296631965786,
        0.03732199361547828,
        0.03762573946733028,
        0.0373385357670486,
        0.037678579334169626,
        0.03732556477189064,
        0.03713312896434218,
        0.03753122768830508,
        0.03713409637566656,
        0.036710083251819015,
        0.03697948646731675,
        0.03668408584780991,
        0.03662169456947595,
        0.036551582044921815,
        0.03647590184118599,
        0.036706024198792875,
        0.03701220895163715,
        0.037023091106675565,
        0.03706928400788456,
        0.03646199428476393,
        0.03675612865481526,
        0.03666026273276657,
        0.036907862522639334,
        0.03651670622639358,
        0.03655461815651506,
        0.03631199547089636,
        0.03640637011267245,
        0.036732663051225245,
        0.03662669367622584,
        0.03653655911330134
      ],
      "train_rec_loss": [
        0.3943795822560787,
        0.2045424710959196,
        0.18443073192611337,
        0.17570023937150836,
        0.17048219591379166,
        0.16629208298400044,
        0.1615586094558239,
        0.15910393092781305,
        0.15315458457916975,
        0.1457584290765226,
        0.13800786016508937,
        0.12929745041765273,
        0.12440425250679255,
        0.11497116298414767,
        0.10619156085886061,
        0.09373338497243822,
        0.08881734753958881,
        0.07613842864520848,
        0.07144977059215307,
        0.06847484945319593,
        0.06270273332484066,
        0.05864044767804444,
        0.05767787399236113,
        0.05620420223567635,
        0.054322551703080535,
        0.052799774217419326,
        0.05093509634025395,
        0.05015012284275144,
        0.04944017750676721,
        0.050873333238996565,
        0.0500002121552825,
        0.04926569841336459,
        0.04661209334153682,
        0.046349435462616384,
        0.045635541435331106,
        0.044639263418503106,
        0.04547391680534929,
        0.04593824013136327,
        0.04463441018015146,
        0.043851940892636776,
        0.0431492745410651,
        0.04235448129475117,
        0.04279364307876676,
        0.043963787029497325,
        0.04192765580955893,
        0.04120460315607488,
        0.041360886418260634,
        0.04128967737779021,
        0.041058548144064844,
        0.040393217583186924,
        0.041169354459270835,
        0.040578093263320625,
        0.03990712354425341,
        0.039422713802196085,
        0.03954122506547719,
        0.03979158482979983,
        0.03979587915819138,
        0.039704321417957544,
        0.03892582328990102,
        0.03907457331661135,
        0.03870791872031987,
        0.039361068746075034,
        0.03846495458856225,
        0.03856241225730628,
        0.03857726766727865,
        0.0381682887673378,
        0.03808304853737354,
        0.03783863713033497,
        0.03804289049003273,
        0.03794315014965832,
        0.03748296631965786,
        0.03732199361547828,
        0.03762573946733028,
        0.0373385357670486,
        0.037678579334169626,
        0.03732556477189064,
        0.03713312896434218,
        0.03753122768830508,
        0.03713409637566656,
        0.036710083251819015,
        0.03697948646731675,
        0.03668408584780991,
        0.03662169456947595,
        0.036551582044921815,
        0.03647590184118599,
        0.036706024198792875,
        0.03701220895163715,
        0.037023091106675565,
        0.03706928400788456,
        0.03646199428476393,
        0.03675612865481526,
        0.03666026273276657,
        0.036907862522639334,
        0.03651670622639358,
        0.03655461815651506,
        0.03631199547089636,
        0.03640637011267245,
        0.036732663051225245,
        0.03662669367622584,
        0.03653655911330134
      ],
      "train_disc_loss": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100
      ]
    }
  },
  {
    "experiment_name": "Ablation_StudentOnly",
    "config": {
      "seq_length": 100,
      "num_features": 5,
      "num_train_samples": 1000,
      "num_test_samples": 300,
      "train_anomaly_ratio": 0.05,
      "test_anomaly_ratio": 0.25,
      "d_model": 64,
      "nhead": 4,
      "num_encoder_layers": 3,
      "num_teacher_decoder_layers": 4,
      "num_student_decoder_layers": 1,
      "dim_feedforward": 256,
      "dropout": 0.1,
      "masking_ratio": 0.6,
      "masking_strategy": "patch",
      "patch_size": 10,
      "margin": 1.0,
      "lambda_disc": 0.5,
      "batch_size": 32,
      "num_epochs": 100,
      "learning_rate": 0.001,
      "weight_decay": 1e-05,
      "warmup_epochs": 10,
      "mask_last_n": 10,
      "use_discrepancy_loss": false,
      "use_teacher": false,
      "use_student": true,
      "use_masking": true,
      "random_seed": 42,
      "device": "cuda"
    },
    "metrics": {
      "sequence": {
        "roc_auc": 0.701274074074074,
        "precision": 0.4479166666666667,
        "recall": 0.5733333333333334,
        "f1_score": 0.5029239766081871,
        "optimal_threshold": 0.008469062857329845
      },
      "point": {
        "roc_auc": 0.7340738444717906,
        "precision": 0.2065761258041458,
        "recall": 0.559427022841657,
        "f1_score": 0.3017331384422635,
        "optimal_threshold": 0.011935857124626637
      },
      "combined": {
        "roc_auc": 0.7135734466604559,
        "precision": 0.3574179468197216,
        "recall": 0.5681186964024922,
        "f1_score": 0.4274807326597041,
        "seq_weight": 0.6250165035533857,
        "point_weight": 0.3749834964466142
      }
    },
    "history": {
      "train_loss": [
        0.42122287256643176,
        0.20545032806694508,
        0.18728270940482616,
        0.17858029808849096,
        0.17174143949523568,
        0.16986912675201893,
        0.16748885018751025,
        0.16513217287138104,
        0.16376054240390658,
        0.1594373034313321,
        0.15678655728697777,
        0.1518133981153369,
        0.14787158137187362,
        0.14282284956425428,
        0.13334082695655525,
        0.12604884011670947,
        0.11600923794321716,
        0.10798883880488575,
        0.0981905055232346,
        0.09204548317939043,
        0.08823004877194762,
        0.0825762499589473,
        0.08047458459623158,
        0.0782188808079809,
        0.07495079701766372,
        0.07191567029803991,
        0.07109970052260906,
        0.0680573444114998,
        0.06485322839580476,
        0.06362610857468098,
        0.06312652595806867,
        0.06265033921226859,
        0.06049631373025477,
        0.05819110304582864,
        0.058561486192047596,
        0.05711121310014278,
        0.05676538881380111,
        0.05582572112325579,
        0.05636126536410302,
        0.05393824027851224,
        0.05374916328582913,
        0.05364893947262317,
        0.05247039976529777,
        0.05216307647060603,
        0.05211305455304682,
        0.051193196908570826,
        0.050809962092898786,
        0.050519252312369645,
        0.05153696786146611,
        0.04986915609333664,
        0.04984820866957307,
        0.04969814885407686,
        0.04811567405704409,
        0.04849635832943022,
        0.048355411272495985,
        0.048156799166463315,
        0.047601440572179854,
        0.047503095818683505,
        0.04769228328950703,
        0.04730136424768716,
        0.0459919658023864,
        0.046645911294035614,
        0.04568316519726068,
        0.04614389734342694,
        0.046156253782100976,
        0.04494951129890978,
        0.04483028477989137,
        0.04505963786505163,
        0.045265620457939804,
        0.044813579646870494,
        0.04477024939842522,
        0.04450854379683733,
        0.045146197779104114,
        0.044146296102553606,
        0.044336062972433865,
        0.04421230417210609,
        0.043892877525649965,
        0.04415551631245762,
        0.043903306825086474,
        0.04426941892597824,
        0.04337814042810351,
        0.04425371577963233,
        0.043742515379562974,
        0.043706820462830365,
        0.04360828537028283,
        0.04407553235068917,
        0.04293232539203018,
        0.04361358564347029,
        0.04281681519933045,
        0.043448525364510715,
        0.04336307931225747,
        0.04299998062197119,
        0.04347393044736236,
        0.042729857261292636,
        0.043068263796158135,
        0.04281903640367091,
        0.04307874955702573,
        0.04327524115797132,
        0.04366514703724533,
        0.04356438422109932
      ],
      "train_rec_loss": [
        0.42122287256643176,
        0.20545032806694508,
        0.18728270940482616,
        0.17858029808849096,
        0.17174143949523568,
        0.16986912675201893,
        0.16748885018751025,
        0.16513217287138104,
        0.16376054240390658,
        0.1594373034313321,
        0.15678655728697777,
        0.1518133981153369,
        0.14787158137187362,
        0.14282284956425428,
        0.13334082695655525,
        0.12604884011670947,
        0.11600923794321716,
        0.10798883880488575,
        0.0981905055232346,
        0.09204548317939043,
        0.08823004877194762,
        0.0825762499589473,
        0.08047458459623158,
        0.0782188808079809,
        0.07495079701766372,
        0.07191567029803991,
        0.07109970052260906,
        0.0680573444114998,
        0.06485322839580476,
        0.06362610857468098,
        0.06312652595806867,
        0.06265033921226859,
        0.06049631373025477,
        0.05819110304582864,
        0.058561486192047596,
        0.05711121310014278,
        0.05676538881380111,
        0.05582572112325579,
        0.05636126536410302,
        0.05393824027851224,
        0.05374916328582913,
        0.05364893947262317,
        0.05247039976529777,
        0.05216307647060603,
        0.05211305455304682,
        0.051193196908570826,
        0.050809962092898786,
        0.050519252312369645,
        0.05153696786146611,
        0.04986915609333664,
        0.04984820866957307,
        0.04969814885407686,
        0.04811567405704409,
        0.04849635832943022,
        0.048355411272495985,
        0.048156799166463315,
        0.047601440572179854,
        0.047503095818683505,
        0.04769228328950703,
        0.04730136424768716,
        0.0459919658023864,
        0.046645911294035614,
        0.04568316519726068,
        0.04614389734342694,
        0.046156253782100976,
        0.04494951129890978,
        0.04483028477989137,
        0.04505963786505163,
        0.045265620457939804,
        0.044813579646870494,
        0.04477024939842522,
        0.04450854379683733,
        0.045146197779104114,
        0.044146296102553606,
        0.044336062972433865,
        0.04421230417210609,
        0.043892877525649965,
        0.04415551631245762,
        0.043903306825086474,
        0.04426941892597824,
        0.04337814042810351,
        0.04425371577963233,
        0.043742515379562974,
        0.043706820462830365,
        0.04360828537028283,
        0.04407553235068917,
        0.04293232539203018,
        0.04361358564347029,
        0.04281681519933045,
        0.043448525364510715,
        0.04336307931225747,
        0.04299998062197119,
        0.04347393044736236,
        0.042729857261292636,
        0.043068263796158135,
        0.04281903640367091,
        0.04307874955702573,
        0.04327524115797132,
        0.04366514703724533,
        0.04356438422109932
      ],
      "train_disc_loss": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100
      ]
    }
  },
  {
    "experiment_name": "Ablation_NoMasking",
    "config": {
      "seq_length": 100,
      "num_features": 5,
      "num_train_samples": 1000,
      "num_test_samples": 300,
      "train_anomaly_ratio": 0.05,
      "test_anomaly_ratio": 0.25,
      "d_model": 64,
      "nhead": 4,
      "num_encoder_layers": 3,
      "num_teacher_decoder_layers": 4,
      "num_student_decoder_layers": 1,
      "dim_feedforward": 256,
      "dropout": 0.1,
      "masking_ratio": 0.6,
      "masking_strategy": "patch",
      "patch_size": 10,
      "margin": 1.0,
      "lambda_disc": 0.5,
      "batch_size": 32,
      "num_epochs": 100,
      "learning_rate": 0.001,
      "weight_decay": 1e-05,
      "warmup_epochs": 10,
      "mask_last_n": 10,
      "use_discrepancy_loss": true,
      "use_teacher": true,
      "use_student": true,
      "use_masking": false,
      "random_seed": 42,
      "device": "cuda"
    },
    "metrics": {
      "sequence": {
        "roc_auc": 0.7404444444444445,
        "precision": 0.40425531914893614,
        "recall": 0.76,
        "f1_score": 0.5277777777777778,
        "optimal_threshold": 2.0749967006850056e-05
      },
      "point": {
        "roc_auc": 0.5210084677350403,
        "precision": 0.1070389761489238,
        "recall": 0.21370499419279906,
        "f1_score": 0.14263565891472868,
        "optimal_threshold": 2.628362926770933e-05
      },
      "combined": {
        "roc_auc": 0.6937577382800231,
        "precision": 0.3410202367299703,
        "recall": 0.6437715000171227,
        "f1_score": 0.4458358045218891,
        "seq_weight": 0.7872422432067835,
        "point_weight": 0.2127577567932164
      }
    },
    "history": {
      "train_loss": [
        0.030388114450033754,
        0.04457630320393946,
        0.07953568588709459,
        0.12018066362361424,
        0.17704609083739342,
        0.19685600975208217,
        0.23566604186635232,
        0.2853015819018765,
        0.36318547544942703,
        0.3806937420667964,
        0.4239306673989631,
        0.36076265891460935,
        0.3599540129835077,
        0.39117030474881176,
        0.4065772329631727,
        0.4221294609051256,
        0.3599674430406594,
        0.42237597721396014,
        0.3753698064610944,
        0.35963826881743444,
        0.42204975565437053,
        0.4064192021578492,
        0.40642873185061035,
        0.39086556484653556,
        0.4063740168221557,
        0.40640178616013145,
        0.42208174862935266,
        0.3908076378465921,
        0.3755081500275992,
        0.42204582234626287,
        0.4063876595846523,
        0.37513078749998385,
        0.35953583222089947,
        0.37517626933004067,
        0.4063679938280984,
        0.3908976930069912,
        0.37508585939485783,
        0.406317967825089,
        0.39150356369100336,
        0.34402095141831524,
        0.4063307573869679,
        0.4063329044556667,
        0.4219212049383714,
        0.42198551223646064,
        0.4219596575412652,
        0.40632321323573706,
        0.42193818438227026,
        0.4063181344426994,
        0.40631528181438625,
        0.40630194402456254,
        0.39068184894131264,
        0.40630570626308327,
        0.35946337934365147,
        0.39068426696394454,
        0.3906961579432391,
        0.3750723296607248,
        0.4063019520499438,
        0.3438158756257508,
        0.3906824555565436,
        0.39068962085821113,
        0.40629121760184717,
        0.42189942444429107,
        0.4062826758868141,
        0.37506080057573854,
        0.3594262136480211,
        0.4219143097761844,
        0.4062977370331282,
        0.42190052433306846,
        0.45311920230778924,
        0.40629616776095645,
        0.40627851442650353,
        0.4219134875615964,
        0.4375327295192619,
        0.34378977262213084,
        0.39066436143366445,
        0.4062709807435567,
        0.4375360450089829,
        0.3906544029678116,
        0.2969472868298908,
        0.43752489777853043,
        0.39066461251286455,
        0.421918668167109,
        0.4531479581482927,
        0.46870424594681026,
        0.4375068834974627,
        0.421907762380215,
        0.45315268810327325,
        0.4375133043590722,
        0.3906596884330611,
        0.40628667737291835,
        0.37505137562129676,
        0.35942922185631687,
        0.40627174234941776,
        0.4062779158853118,
        0.43753638970429165,
        0.40627655572461663,
        0.39065620380688415,
        0.4531543203379442,
        0.4219085004783665,
        0.40628830962987195
      ],
      "train_rec_loss": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "train_disc_loss": [
        0.06077622890006751,
        0.08915260640787892,
        0.15907137177418917,
        0.24036132724722847,
        0.35409218167478684,
        0.39371201950416435,
        0.47133208373270463,
        0.570603163803753,
        0.7263709508988541,
        0.7613874841335928,
        0.8478613347979262,
        0.7215253178292187,
        0.7199080259670154,
        0.7823406094976235,
        0.8131544659263454,
        0.8442589218102512,
        0.7199348860813188,
        0.8447519544279203,
        0.7507396129221888,
        0.7192765376348689,
        0.8440995113087411,
        0.8128384043156984,
        0.8128574637012207,
        0.7817311296930711,
        0.8127480336443114,
        0.8128035723202629,
        0.8441634972587053,
        0.7816152756931842,
        0.7510163000551984,
        0.8440916446925257,
        0.8127753191693046,
        0.7502615749999677,
        0.7190716644417989,
        0.7503525386600813,
        0.8127359876561968,
        0.7817953860139824,
        0.7501717187897157,
        0.812635935650178,
        0.7830071273820067,
        0.6880419028366305,
        0.8126615147739358,
        0.8126658089113334,
        0.8438424098767427,
        0.8439710244729213,
        0.8439193150825304,
        0.8126464264714741,
        0.8438763687645405,
        0.8126362688853987,
        0.8126305636287725,
        0.8126038880491251,
        0.7813636978826253,
        0.8126114125261665,
        0.7189267586873029,
        0.7813685339278891,
        0.7813923158864782,
        0.7501446593214496,
        0.8126039040998876,
        0.6876317512515016,
        0.7813649111130871,
        0.7813792417164223,
        0.8125824352036943,
        0.8437988488885821,
        0.8125653517736282,
        0.7501216011514771,
        0.7188524272960422,
        0.8438286195523688,
        0.8125954740662564,
        0.8438010486661369,
        0.9062384046155785,
        0.8125923355219129,
        0.8125570288530071,
        0.8438269751231928,
        0.8750654590385238,
        0.6875795452442617,
        0.7813287228673289,
        0.8125419614871134,
        0.8750720900179658,
        0.7813088059356232,
        0.5938945736597816,
        0.8750497955570609,
        0.7813292250257291,
        0.843837336334218,
        0.9062959162965853,
        0.9374084918936205,
        0.8750137669949254,
        0.84381552476043,
        0.9063053762065465,
        0.8750266087181444,
        0.7813193768661222,
        0.8125733547458367,
        0.7501027512425935,
        0.7188584437126337,
        0.8125434846988355,
        0.8125558317706236,
        0.8750727794085833,
        0.8125531114492333,
        0.7813124076137683,
        0.9063086406758885,
        0.843817000956733,
        0.8125766192597439
      ],
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100
      ]
    }
  }
]